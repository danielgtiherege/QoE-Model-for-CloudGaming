{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0ea2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import logging\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "np.random.seed(0)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print(tf.__version__)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "dispositivoUsado = '/cpu:0' \n",
    "#dispositivoUsado = '/gpu:0'\n",
    "exibirRodando = False\n",
    "QuantasThreadsFinalizaram = 0\n",
    "anonimo = False\n",
    "plt.rcParams['figure.dpi'] = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a9894f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    }
   ],
   "source": [
    "dados = pd.read_csv('dados-Ambos-Tudo.csv')\n",
    "dados[\"QoE\"] = dados[\"QoE\"] + 3\n",
    "\n",
    "#---------------------------------------------------------\n",
    "#DROPANDO LINHAS COM USO DE CPU E RAM ALTO\n",
    "\n",
    "dados = dados[dados['UsoCpu'] < 81]\n",
    "dados = dados[dados['UsoRam'] < 81]\n",
    "dados.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#DROPANDO LINHAS COM USO DE CPU E RAM ALTO\n",
    "#---------------------------------------------------------\n",
    "\n",
    "\n",
    "dados = dados.sample(frac=1).reset_index(drop=True)\n",
    "#Salvando quantos jogadores temos e quantas instancias temos\n",
    "\n",
    "\n",
    "\n",
    "dicionarioJogadores = dados['NOME'].value_counts().to_dict()\n",
    "\n",
    "#'NOME'\n",
    "dadosFear = dados[dados['Jogo'] == 'FEAR']\n",
    "dadosHL2 = dados[dados['Jogo'] == 'Half-Life 2']\n",
    "dados = dados[dados['Jogo'] != 'FEAR']\n",
    "numeroInstancias = len(dados)\n",
    "dados.drop(['TempoJogo','UsoCpu', 'UsoRam', 'UsoGpu', 'UsoVram','TerminoPartida','Jogo'], axis=1, inplace=True)\n",
    "dados.dropna(inplace=True)\n",
    "\n",
    "dadosHL2.drop(['TempoJogo','UsoCpu', 'UsoRam', 'UsoGpu', 'UsoVram','TerminoPartida','Jogo'], axis=1, inplace=True)\n",
    "dadosHL2.dropna(inplace=True)\n",
    "\n",
    "dadosFear.drop(['TempoJogo','UsoCpu', 'UsoRam', 'UsoGpu', 'UsoVram','TerminoPartida','Jogo'], axis=1, inplace=True)\n",
    "dadosFear.dropna(inplace=True)\n",
    "porcentagemTeste = 0.2\n",
    "porcentagemValidacao = 0.1\n",
    "NumeroCamadasInternas = 64\n",
    "print(numeroInstancias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18988025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arredondaVetor(vetor):\n",
    " with tf.device(dispositivoUsado):\n",
    "    novoVetor = []\n",
    "    for x in range(len(vetor)):\n",
    "        if(vetor[x]>=0):\n",
    "            floatTeste = vetor[x] - int(vetor[x])\n",
    "            if(floatTeste>=0.5):\n",
    "                novoVetor.append(int(vetor[x])+1)\n",
    "            else:\n",
    "                novoVetor.append(int(vetor[x]))\n",
    "        else:\n",
    "            valor = vetor[x]*(-1.0)\n",
    "            floatTeste = valor - int(valor)\n",
    "            if(floatTeste>=0.5):\n",
    "                novoVetor.append((int(valor)+1)*-1)\n",
    "            else:\n",
    "                novoVetor.append(int(valor)*-1)\n",
    "    return novoVetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3600d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def porcentagemAcerto(vetor1,vetor2):\n",
    " with tf.device(dispositivoUsado):\n",
    "    tamanho = float(len(vetor1))\n",
    "    acertos = float(0)\n",
    "    for x in range(len(vetor1)):\n",
    "        if(vetor1[x]==vetor2[x]):\n",
    "            acertos = acertos + 1.0\n",
    "    acertos = (acertos/tamanho)*100.0\n",
    "    return acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e9b0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodarModeloRF(baseDados):\n",
    "    if 'NOME' in baseDados.columns:\n",
    "        baseDados.drop(['NOME'], axis=1, inplace=True)\n",
    "        baseDados.dropna(inplace=True)\n",
    "    n_estimators = 41\n",
    "    max_features = 3\n",
    "    max_depth = 7\n",
    "    global porcentagemTeste\n",
    "    X = np.asarray(baseDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', 'PerdaVideo', 'PerdaComandos']])\n",
    "    y = np.asarray(baseDados['QoE'])\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_temp = np.zeros((baseDados.shape[0],baseDados.shape[1]))\n",
    "    X_temp[:,:X.shape[1]] = X\n",
    "    X = X_temp\n",
    "    X[:, 6:-1] = np.asarray(baseDados[list(baseDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo','JitterComandos', 'PerdaVideo', 'PerdaComandos', 'QoE'], axis=1))])\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=porcentagemTeste, random_state=1)\n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    modelos = list()\n",
    "    mses = list()\n",
    "    acertos = list()\n",
    "    XT = list()\n",
    "    YT = list()\n",
    "    kFold = StratifiedKFold(n_splits=10)\n",
    "    for train, test in kFold.split(X_train,y_train):\n",
    "        rfr=RandomForestRegressor(n_estimators=n_estimators,max_features=max_features,criterion='mse',bootstrap=True,max_depth=max_depth)\n",
    "        rfr.fit(X_train[train],y_train[train])\n",
    "        y_pred=rfr.predict(X_train[test])#X_test\n",
    "        test_predictions_round = arredondaVetor(y_pred)\n",
    "        porcentagemAcertos = porcentagemAcerto(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"Acerto:\",round(porcentagemAcertos,4))\n",
    "        mse = mean_squared_error(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"MSE: \"+str(mse))\n",
    "        mses.append(mse)\n",
    "        modelos.append(rfr)\n",
    "        acertos.append(porcentagemAcertos)\n",
    "        XT.append(X_train[test])\n",
    "        YT.append(y_train[test])\n",
    "    menorMSE = 99\n",
    "    iMSE = 0\n",
    "    for i in range(len(mses)):\n",
    "        if(mses[i]<menorMSE):\n",
    "            menorMSE = mses[i]\n",
    "            iMSE = i\n",
    "    model = modelos[iMSE]\n",
    "    mse = mses[iMSE]\n",
    "    acerto = acertos[iMSE]\n",
    "    #print(\"Menor MSE: \"+str(mse)+\" com acerto: \"+str(acerto))\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos1 = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    #print(\"Acerto com todos dados:\",round(porcentagemAcertos1,4))\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    #print(\"MSE com todos dados: \"+str(mse1))\n",
    "\n",
    "    return mse,acerto,model,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "513141dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodarModeloRFFear(baseDados):\n",
    "    if 'NOME' in baseDados.columns:\n",
    "        baseDados.drop(['NOME'], axis=1, inplace=True)\n",
    "        baseDados.dropna(inplace=True)\n",
    "    n_estimators = 41\n",
    "    max_features = 3\n",
    "    max_depth = 7\n",
    "    global porcentagemTeste\n",
    "    global porcentagemValidacao\n",
    "    \n",
    "    tempFear = dadosFear.copy(deep=True)\n",
    "    if 'NOME' in tempFear.columns:\n",
    "        tempFear.drop(['NOME'], axis=1, inplace=True)\n",
    "        tempFear.dropna(inplace=True)\n",
    "    \n",
    "    \n",
    "    X = np.asarray(baseDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', 'PerdaVideo', 'PerdaComandos']])\n",
    "    \n",
    "    XFear = np.asarray(tempFear[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', 'PerdaVideo', 'PerdaComandos']])\n",
    "    \n",
    "    y = np.asarray(baseDados['QoE'])\n",
    "    \n",
    "    yFear = np.asarray(tempFear['QoE'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scalerFear = StandardScaler()\n",
    "    \n",
    "    scaler.fit(X)\n",
    "    \n",
    "    scalerFear.fit(XFear)\n",
    "    \n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    XFear = scalerFear.transform(XFear)\n",
    "    \n",
    "    X_temp = np.zeros((baseDados.shape[0],baseDados.shape[1]))\n",
    "    \n",
    "    X_tempFear = np.zeros((tempFear.shape[0],tempFear.shape[1]))\n",
    "    \n",
    "    X_temp[:,:X.shape[1]] = X\n",
    "    \n",
    "    X_tempFear[:,:XFear.shape[1]] = XFear\n",
    "    \n",
    "    X = X_temp\n",
    "    \n",
    "    XFear = X_tempFear\n",
    "    \n",
    "    X[:, 6:-1] = np.asarray(baseDados[list(baseDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo','JitterComandos', 'PerdaVideo', 'PerdaComandos', 'QoE'], axis=1))])\n",
    "    \n",
    "    XFear[:, 6:-1] = np.asarray(tempFear[list(tempFear.drop(['DelayVideo', 'DelayComandos', 'JitterVideo','JitterComandos', 'PerdaVideo', 'PerdaComandos', 'QoE'], axis=1))])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=porcentagemTeste, random_state=1)\n",
    "    \n",
    "    XFear = np.asarray(XFear).astype(np.float32)\n",
    "    yFear = np.asarray(yFear).astype(np.float32)\n",
    "    \n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    modelos = list()\n",
    "    mses = list()\n",
    "    acertos = list()\n",
    "    XT = list()\n",
    "    YT = list()\n",
    "    kFold = StratifiedKFold(n_splits=10)\n",
    "    for train, test in kFold.split(X_train, y_train):\n",
    "        rfr=RandomForestRegressor(n_estimators=n_estimators,max_features=max_features,criterion='mse',bootstrap=True,max_depth=max_depth)\n",
    "        rfr.fit(X_train[train],y_train[train])\n",
    "        y_pred=rfr.predict(X_train[test])#X_test\n",
    "        test_predictions_round = arredondaVetor(y_pred)\n",
    "        porcentagemAcertos = porcentagemAcerto(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"Acerto:\",round(porcentagemAcertos,4))\n",
    "        mse = mean_squared_error(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"MSE: \"+str(mse))\n",
    "        mses.append(mse)\n",
    "        modelos.append(rfr)\n",
    "        acertos.append(porcentagemAcertos)\n",
    "        XT.append(X_train[test])\n",
    "        YT.append(y_train[test])\n",
    "    menorMSE = 99\n",
    "    iMSE = 0\n",
    "    for i in range(len(mses)):\n",
    "        if(mses[i]<menorMSE):\n",
    "            menorMSE = mses[i]\n",
    "            iMSE = i\n",
    "    model = modelos[iMSE]\n",
    "    mse = mses[iMSE]\n",
    "    acerto = acertos[iMSE]\n",
    "    #print(\"Menor MSE: \"+str(mse)+\" com acerto: \"+str(acerto))\n",
    "    y_pred = model.predict(XFear)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos1 = porcentagemAcerto(yFear,test_predictions_round)\n",
    "    #print(\"Acerto com todos dados:\",round(porcentagemAcertos1,4))\n",
    "    mse1 = mean_squared_error(yFear,test_predictions_round)\n",
    "    #print(\"MSE com todos dados: \"+str(mse1))\n",
    "    \n",
    "    return mse,acerto,model,XFear,yFear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cf84151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatMap(test_predictions,y_test,nomeHeatmap):\n",
    "    import seaborn as sns\n",
    "    test_predictions_round = arredondaVetor(test_predictions)\n",
    "    x_axis_labels = ['E. Péssimo','Péssimo','Ruim','Regular','bom','Excelente','Ideal'] # labels for x-axis\n",
    "    y_axis_labels = ['E. Péssimo','Péssimo','Ruim','Regular','bom','Excelente','Ideal'] # labels for y-axis\n",
    "    \n",
    "    heatMatrix = np.zeros((7,7))\n",
    "    for x in range(len(y_test)):\n",
    "        intX = int(test_predictions_round[x])\n",
    "        intY = int(y_test[x])\n",
    "        if(intX > 6):\n",
    "            continue\n",
    "        heatMatrix[intX][intY] = heatMatrix[intX][intY] +1\n",
    "                \n",
    "    sns.heatmap(heatMatrix, xticklabels=x_axis_labels, yticklabels=y_axis_labels, cmap=\"Greys\")\n",
    "    plt.savefig(nomeHeatmap+'.png', transparent=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bc084e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_melhor(y_test, test_predictions,history,tipo):\n",
    " with tf.device(dispositivoUsado):\n",
    "    histi = pd.DataFrame(history.history)\n",
    "    histi['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Erro Médio Absoluto [QoE]')\n",
    "    plt.plot(histi['epoch'], histi['mae'],label='Erro de Treino')\n",
    "    plt.plot(histi['epoch'], histi['val_mae'],label = 'Erro de Validação')\n",
    "    plt.ylim([0,5])\n",
    "    plt.legend()\n",
    "    plt.savefig('melhor'+tipo+'ResSemAcordoMAE.png')\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "    plt.figure()\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Erro Médio Quadratico [$QoE^2$]')\n",
    "    plt.plot(histi['epoch'], histi['mse'],label='Erro de Treino')\n",
    "    plt.plot(histi['epoch'], histi['val_mse'],label = 'Erro de Validação')\n",
    "    plt.ylim([0,20])\n",
    "    plt.legend()\n",
    "    plt.savefig('melhor'+tipo+'ResSemAcordoMSE.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(y_test, test_predictions)\n",
    "    plt.xlabel('Valores Reais [QoE]')\n",
    "    plt.ylabel('Predicões [QoE]')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.xlim([0,plt.xlim()[1]])\n",
    "    plt.ylim([0,plt.ylim()[1]])\n",
    "    _ = plt.plot([-100, 100], [-100, 100])\n",
    "    plt.savefig('melhor'+tipo+'ResSemAcordoPredicoesSemArredondar.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    test_predictions_round = arredondaVetor(test_predictions)\n",
    "    print(\"Porcentagem de acertos arredondado: \"+str(porcentagemAcerto(y_test,test_predictions_round)))\n",
    "    plt.figure()\n",
    "    plt.scatter(y_test, test_predictions_round)\n",
    "    plt.xlabel('Valores Reais [QoE]')\n",
    "    plt.ylabel('Predicões Arredondadas [QoE]')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.xlim([0,plt.xlim()[1]])\n",
    "    plt.ylim([0,plt.ylim()[1]])\n",
    "    _ = plt.plot([-100, 100], [-100, 100])\n",
    "    plt.savefig('melhor'+tipo+'ResSemAcordoPredicoesArredondado.png')\n",
    "    plt.show()\n",
    "    \n",
    "    plot_heatMap(test_predictions,y_test,\"HeatMap_\"+tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ed0a741",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . "
     ]
    }
   ],
   "source": [
    "repeticoes = 30\n",
    "mse,acerto,model,X_test,y_test = rodarModeloRF(dados)\n",
    "    for ABA in range(repeticoes):\n",
    "        mse1,acerto1,model1,X_test1,y_test1 = rodarModeloRFFear(dados)\n",
    "        if(mse1<mse):\n",
    "            mse = mse1\n",
    "            acerto = acerto1\n",
    "            X_test = X_test1\n",
    "            y_test = y_test1\n",
    "            model = model1\n",
    "\n",
    "\n",
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51b7ad5",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
