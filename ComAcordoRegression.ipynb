{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0ea2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import logging\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "np.random.seed(0)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "print(tf.__version__)\n",
    "QuantasThreadsFinalizaram = 0\n",
    "exibirRodando = False\n",
    "anonimo = True\n",
    "FearValidaComHL2 = True # Ao validar usa na mesma categoria de HL2\n",
    "soHL2 = False # Ao treina o modelo do Fear deleta instancias de Spelunky\n",
    "comHora = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a9894f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    }
   ],
   "source": [
    "dispositivoUsado = '/cpu:0' \n",
    "#dispositivoUsado = '/gpu:0'\n",
    "\n",
    "\n",
    "dados = pd.read_csv('dados-Ambos-Tudo.csv')\n",
    "\n",
    "#QoE agora entre 0 e 6\n",
    "dados[\"QoE\"] = dados[\"QoE\"] + 3\n",
    "\n",
    "\n",
    "#DROPANDO LINHAS COM USO DE CPU E RAM ALTO\n",
    "dados = dados[dados['UsoCpu'] < 81]\n",
    "dados = dados[dados['UsoRam'] < 81]\n",
    "numeroInstancias = len(dados[dados['Jogo'] != 'FEAR'])\n",
    "\n",
    "#Modificand a data e hora de jogo para ser somente a hora\n",
    "if(comHora):\n",
    "    dados['TerminoPartida'] = dados['TerminoPartida'].str.split('-')\n",
    "    dados['TerminoPartida'] = dados['TerminoPartida'].str[3]\n",
    "\n",
    "#Embaralha os dados\n",
    "\n",
    "    \n",
    "#DROPANDO DADOS NÃO UTILIZADOS PELO MODELO\n",
    "print(numeroInstancias)\n",
    "\n",
    "if(comHora):\n",
    "    dados.drop(['TempoJogo','UsoCpu', 'UsoRam', 'UsoGpu', 'UsoVram'], axis=1, inplace=True)\n",
    "else:\n",
    "    dados.drop(['TempoJogo','UsoCpu', 'UsoRam', 'UsoGpu', 'UsoVram','TerminoPartida'], axis=1, inplace=True)\n",
    "dados.dropna(inplace=True)\n",
    "dados = dados.sample(frac=1).reset_index(drop=True)\n",
    "porcentagemTeste = 0.2\n",
    "porcentagemValidacao = 0.1\n",
    "NumeroCamadasInternas = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caecd75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_1(X_train):\n",
    "    with tf.device(dispositivoUsado):\n",
    "      model = keras.Sequential([\n",
    "        layers.Dense(NumeroCamadasInternas, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='relu'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='relu'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='relu'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "    \n",
    "      optimizer = 'adam'\n",
    "\n",
    "      model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3ce5498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tipos: elu, exponential, selu, tanh, softsign, softplus, softmax, sigmoid, relu\n",
    "def build_model_2(X_train):\n",
    "  with tf.device(dispositivoUsado):\n",
    "      model = keras.Sequential([\n",
    "        layers.Dense(NumeroCamadasInternas, activation='linear', input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='linear'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='linear'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='linear'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='linear'),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "\n",
    "      optimizer = 'adam'\n",
    "\n",
    "      model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6defcecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tipos: elu, exponential, selu, tanh, softsign, softplus, softmax, sigmoid, relu\n",
    "def build_model_3(X_train):\n",
    "  with tf.device(dispositivoUsado):\n",
    "      model = keras.Sequential([\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softmax', input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softmax'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softmax'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softmax'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softmax'),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "\n",
    "      optimizer = 'adam'\n",
    "\n",
    "      model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b42b4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tipos: elu, exponential, selu, tanh, softsign, softplus, softmax, sigmoid, relu\n",
    "def build_model_4(X_train):\n",
    "  with tf.device(dispositivoUsado):\n",
    "      model = keras.Sequential([\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softplus', input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softplus'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softplus'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softplus'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softplus'),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "\n",
    "      optimizer = 'adam'\n",
    "\n",
    "      model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0030b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tipos: elu, exponential, selu, tanh, softsign, softplus, softmax, sigmoid, relu\n",
    "def build_model_5(X_train):\n",
    "  with tf.device(dispositivoUsado):\n",
    "      model = keras.Sequential([\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softsign', input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softsign'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softsign'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softsign'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='softsign'),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "\n",
    "      optimizer = 'adam'\n",
    "\n",
    "      model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54dc3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tipos: elu, exponential, selu, tanh, softsign, softplus, softmax, sigmoid, relu\n",
    "def build_model_6(X_train):\n",
    "  with tf.device(dispositivoUsado):\n",
    "      model = keras.Sequential([\n",
    "        layers.Dense(NumeroCamadasInternas, activation='tanh', input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='tanh'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='tanh'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='tanh'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='tanh'),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "\n",
    "      optimizer = 'adam'\n",
    "\n",
    "      model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2270e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tipos: elu, exponential, selu, tanh, softsign, softplus, softmax, sigmoid, relu\n",
    "def build_model_7(X_train):\n",
    "  with tf.device(dispositivoUsado):\n",
    "      model = keras.Sequential([\n",
    "        layers.Dense(NumeroCamadasInternas, activation='selu', input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='selu'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='selu'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='selu'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='selu'),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "\n",
    "      optimizer = 'adam'\n",
    "\n",
    "      model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51f509cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tipos: elu, exponential, selu, tanh, softsign, softplus, softmax, sigmoid, relu\n",
    "def build_model_8(X_train):\n",
    "  with tf.device(dispositivoUsado):\n",
    "      model = keras.Sequential([\n",
    "        layers.Dense(NumeroCamadasInternas, activation='gelu', input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='gelu'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='gelu'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='gelu'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='gelu'),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "\n",
    "      optimizer = 'adam'\n",
    "\n",
    "      model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd92204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tipos: elu, exponential, selu, tanh, softsign, softplus, softmax, sigmoid, relu\n",
    "def build_model_9(X_train):\n",
    "  with tf.device(dispositivoUsado):\n",
    "      model = keras.Sequential([\n",
    "        layers.Dense(NumeroCamadasInternas, activation='elu', input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='elu'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='elu'),\n",
    "        layers.Dense(NumeroCamadasInternas, activation='elu'),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "\n",
    "      optimizer = 'adam'\n",
    "\n",
    "      model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a77b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arredondar os valores de um vetor (X.4 -> X e X.5 -> X+1)\n",
    "def arredondaVetor(vetor):\n",
    "  with tf.device(dispositivoUsado):\n",
    "    novoVetor = []\n",
    "    for x in range(len(vetor)):\n",
    "        if(vetor[x]>=0):\n",
    "            floatTeste = vetor[x] - int(vetor[x])\n",
    "            if(floatTeste>=0.5):\n",
    "                novoVetor.append(int(vetor[x])+1)\n",
    "            else:\n",
    "                novoVetor.append(int(vetor[x]))\n",
    "        else:\n",
    "            valor = vetor[x]*(-1.0)\n",
    "            floatTeste = valor - int(valor)\n",
    "            if(floatTeste>=0.5):\n",
    "                novoVetor.append((int(valor)+1)*-1)\n",
    "            else:\n",
    "                novoVetor.append(int(valor)*-1)\n",
    "    return novoVetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "526c7448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arredondar os valores de um vetor (Compara vetor1 com 2 e retorna Float entre 0 e 100)\n",
    "def porcentagemAcerto(vetor1,vetor2):\n",
    "  with tf.device(dispositivoUsado):\n",
    "    tamanho = float(len(vetor1))\n",
    "    acertos = float(0)\n",
    "    for x in range(len(vetor1)):\n",
    "        if(vetor1[x]==vetor2[x]):\n",
    "            acertos = acertos + 1.0\n",
    "    acertos = (acertos/tamanho)*100.0\n",
    "    return acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6dc6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo tensorFlow Regression\n",
    "def rodarModelo(numero,baseDados):\n",
    " with tf.device(dispositivoUsado):\n",
    "    global porcentagemTeste\n",
    "    global porcentagemValidacao\n",
    "    \n",
    "    tempDados = baseDados.copy(deep=True)\n",
    "    tempDados = tempDados[tempDados['Jogo'] != 'FEAR']\n",
    "    tempDados[\"NOME\"].unique()\n",
    "    tempDados[\"Jogo\"].unique()\n",
    "    dummies_jogador = pd.get_dummies(tempDados[\"NOME\"])\n",
    "    dummies_jogo = pd.get_dummies(tempDados[\"Jogo\"])\n",
    "    tempDados.drop([\"NOME\", \"Jogo\"], axis=1, inplace=True)\n",
    "    tempDados = tempDados.join(dummies_jogador)\n",
    "    tempDados = tempDados.join(dummies_jogo)\n",
    "    if(comHora):\n",
    "        X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos','TerminoPartida']])\n",
    "    else:\n",
    "        X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos']])\n",
    "    y = np.asarray(tempDados['QoE'])\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_temp = np.zeros((tempDados.shape[0],tempDados.shape[1]))\n",
    "    X_temp[:,:X.shape[1]] = X\n",
    "    X = X_temp\n",
    "    if(comHora):\n",
    "        X[:, 7:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','TerminoPartida','QoE'], axis=1))])\n",
    "    else:\n",
    "        X[:, 6:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','QoE'], axis=1))])\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=porcentagemTeste, random_state=1)\n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    \n",
    "    class PrintDot(keras.callbacks.Callback):\n",
    "      #def on_epoch_end(self, epoch, logs):\n",
    "      #  if epoch % 100 == 0: print('')\n",
    "      #  print('.', end='')\n",
    "        def on_train_end(self, logs=None):\n",
    "            global QuantasThreadsFinalizaram\n",
    "            QuantasThreadsFinalizaram = QuantasThreadsFinalizaram + 1\n",
    "            print(\"\\nIterações Rodadas: \"+str(QuantasThreadsFinalizaram)+\"\\n\")\n",
    "\n",
    "\n",
    "    EPOCHS = 1000\n",
    "    \n",
    "    verbose = 0\n",
    "    if(exibirRodando):\n",
    "        verbose = 1\n",
    "    \n",
    "\n",
    "    modelos = list()\n",
    "    mses = list()\n",
    "    losss = list()\n",
    "    maes = list()\n",
    "    historys = list()\n",
    "    kFold = StratifiedKFold(n_splits=10)\n",
    "    start = time.process_time()#Contar tempo de execução\n",
    "    for train, test in kFold.split(X, y):#X_train, y_train\n",
    "\n",
    "        model = build_model_1(X[train])\n",
    "        if(numero == 1):\n",
    "            model = build_model_1(X[train])\n",
    "        elif(numero == 2):\n",
    "            model = build_model_2(X[train])\n",
    "        elif(numero == 3):\n",
    "            model = build_model_3(X[train])\n",
    "        elif(numero == 4):\n",
    "            model = build_model_4(X[train])\n",
    "        elif(numero == 5):\n",
    "            model = build_model_5(X[train])\n",
    "        elif(numero == 6):\n",
    "            model = build_model_6(X[train])\n",
    "        elif(numero == 7):\n",
    "            model = build_model_7(X[train])\n",
    "        elif(numero == 8):\n",
    "            model = build_model_8(X[train])\n",
    "        elif(numero == 9):\n",
    "            model = build_model_9(X[train])\n",
    "            \n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=verbose)\n",
    "    \n",
    "        history = model.fit(X[train], y[train], epochs=EPOCHS,\n",
    "                        validation_split = porcentagemValidacao, verbose=verbose, callbacks=[early_stop])\n",
    "        loss, mae, mse = model.evaluate(X[test], y[test], verbose=verbose)\n",
    "        mses.append(mse)\n",
    "        modelos.append(model)\n",
    "        losss.append(loss)\n",
    "        maes.append(mae)\n",
    "        historys.append(history)\n",
    "    menorMSE = 99\n",
    "    iMSE = 0\n",
    "    for i in range(len(mses)):\n",
    "        if(mses[i]<menorMSE):\n",
    "            menorMSE = mses[i]\n",
    "            iMSE = i\n",
    "    model = modelos[iMSE]\n",
    "    mse = mses[iMSE]\n",
    "    mae = maes[iMSE]\n",
    "    loss = losss[iMSE]\n",
    "    history = historys[iMSE]\n",
    "    global QuantasThreadsFinalizaram\n",
    "    print(str(QuantasThreadsFinalizaram)+\": MSE: \"+str(round(mse,4))+\" tempo: \"+str(round(time.process_time() - start,2)))\n",
    "    QuantasThreadsFinalizaram = QuantasThreadsFinalizaram + 1\n",
    "    \n",
    "    if(exibirRodando):\n",
    "        print(\"Conjunto de testes Mean Abs Error: {:5.2f} QoE\".format(mae))\n",
    "\n",
    "    test_predictions = model.predict(X_test,verbose).flatten()\n",
    "\n",
    "    test_predictions_round = arredondaVetor(test_predictions)\n",
    "    porcentagemAcertos = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    if(exibirRodando):\n",
    "        plt.scatter(y_test, test_predictions)\n",
    "        #Fazer um MSE e MAE destes dados, para ter também da predição.\n",
    "        plt.xlabel('Valores Reais [QoE]')\n",
    "        plt.ylabel('Predicões [QoE]')\n",
    "        plt.axis('equal')\n",
    "        plt.axis('square')\n",
    "        plt.xlim([0,plt.xlim()[1]])\n",
    "        plt.ylim([0,plt.ylim()[1]])\n",
    "        _ = plt.plot([-100, 100], [-100, 100])\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Porcentagem de acertos arredondado: \"+str(porcentagemAcertos))\n",
    "    \n",
    "        plt.figure()\n",
    "        plt.scatter(y_test, test_predictions_round)\n",
    "        plt.xlabel('Valores Reais [QoE]')\n",
    "        plt.ylabel('Predicões Arredondadas [QoE]')\n",
    "        plt.axis('equal')\n",
    "        plt.axis('square')\n",
    "        plt.xlim([0,plt.xlim()[1]])\n",
    "        plt.ylim([0,plt.ylim()[1]])\n",
    "        _ = plt.plot([-100, 100], [-100, 100])\n",
    "        plt.show()\n",
    "    \n",
    "    resultado = []\n",
    "    resultado.append(loss)\n",
    "    resultado.append(mae)\n",
    "    resultado.append(mse)\n",
    "    resultado.append(porcentagemAcertos)\n",
    "    return resultado,y_test,test_predictions,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c0cf7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodarModeloRF(baseDados):\n",
    "    n_estimators = 46\n",
    "    max_features = 6\n",
    "    max_depth = 9\n",
    "    global porcentagemTeste\n",
    "    tempDados = baseDados.copy(deep=True)\n",
    "    tempDados = tempDados[tempDados['Jogo'] != 'FEAR']\n",
    "    tempDados[\"NOME\"].unique()\n",
    "    tempDados[\"Jogo\"].unique()\n",
    "    dummies_jogador = pd.get_dummies(tempDados[\"NOME\"])\n",
    "    dummies_jogo = pd.get_dummies(tempDados[\"Jogo\"])\n",
    "    tempDados.drop([\"NOME\", \"Jogo\"], axis=1, inplace=True)\n",
    "    tempDados = tempDados.join(dummies_jogador)\n",
    "    tempDados = tempDados.join(dummies_jogo)\n",
    "    if(comHora):\n",
    "        X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos','TerminoPartida']])\n",
    "    else:\n",
    "        X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos']])\n",
    "    y = np.asarray(tempDados['QoE'])\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_temp = np.zeros((tempDados.shape[0],tempDados.shape[1]))\n",
    "    X_temp[:,:X.shape[1]] = X\n",
    "    X = X_temp\n",
    "    if(comHora):\n",
    "        X[:, 7:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','TerminoPartida','QoE'], axis=1))])\n",
    "    else:\n",
    "        X[:, 6:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','QoE'], axis=1))])\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=porcentagemTeste, random_state=1)\n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    modelos = list()\n",
    "    mses = list()\n",
    "    acertos = list()\n",
    "    XT = list()\n",
    "    YT = list()\n",
    "    kFold = StratifiedKFold(n_splits=10)\n",
    "    for train, test in kFold.split(X_train, y_train):\n",
    "        rfr=RandomForestRegressor(n_estimators=n_estimators,max_features=max_features,criterion='mse',bootstrap=True,max_depth=max_depth)\n",
    "        rfr.fit(X_train[train],y_train[train])\n",
    "        y_pred=rfr.predict(X_train[test])#X_test\n",
    "        test_predictions_round = arredondaVetor(y_pred)\n",
    "        porcentagemAcertos = porcentagemAcerto(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"Acerto:\",round(porcentagemAcertos,4))\n",
    "        mse = mean_squared_error(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"MSE: \"+str(mse))\n",
    "        mses.append(mse)\n",
    "        modelos.append(rfr)\n",
    "        acertos.append(porcentagemAcertos)\n",
    "        XT.append(X_train[test])\n",
    "        YT.append(y_train[test])\n",
    "    menorMSE = 99\n",
    "    iMSE = 0\n",
    "    for i in range(len(mses)):\n",
    "        if(mses[i]<menorMSE):\n",
    "            menorMSE = mses[i]\n",
    "            iMSE = i\n",
    "    model = modelos[iMSE]\n",
    "    mse = mses[iMSE]\n",
    "    acerto = acertos[iMSE]\n",
    "    #print(\"Menor MSE: \"+str(mse)+\" com acerto: \"+str(acerto))\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos1 = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    #print(\"Acerto com todos dados:\",round(porcentagemAcertos1,4))\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    #print(\"MSE com todos dados: \"+str(mse1))\n",
    "        \n",
    "    return mse,acerto,model,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bef30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodarModeloRFcomFear(baseDados):\n",
    "    n_estimators = 46\n",
    "    max_features = 6\n",
    "    max_depth = 9\n",
    "    global porcentagemTeste\n",
    "    tempDados = baseDados.copy(deep=True)\n",
    "    if(soHL2):\n",
    "        tempDados = tempDados[tempDados['Jogo'] != 'Spelunky']\n",
    "    tempDados[\"NOME\"].unique()\n",
    "    tempDados[\"Jogo\"].unique()\n",
    "    dummies_jogador = pd.get_dummies(tempDados[\"NOME\"])\n",
    "    dummies_jogo = pd.get_dummies(tempDados[\"Jogo\"])\n",
    "    \n",
    "    tempDados.drop([\"NOME\", \"Jogo\"], axis=1, inplace=True)\n",
    "    \n",
    "    tempDados = tempDados.join(dummies_jogador)\n",
    "    tempDados = tempDados.join(dummies_jogo)\n",
    "    \n",
    "    dadosFear = tempDados[tempDados['FEAR'] == 1]\n",
    "    tempDados = tempDados[tempDados['FEAR'] != 1]\n",
    "    \n",
    "    if(FearValidaComHL2):\n",
    "        tempDados.drop('FEAR', axis=1, inplace=True)\n",
    "        dadosFear['Half-Life 2'] = 1\n",
    "        dadosFear.drop('FEAR', axis=1, inplace=True)\n",
    "\n",
    "    if(comHora):\n",
    "        X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos','TerminoPartida']])\n",
    "    \n",
    "        XFear = np.asarray(dadosFear[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos','TerminoPartida']])\n",
    "    else:\n",
    "        X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos']])\n",
    "    \n",
    "        XFear = np.asarray(dadosFear[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos']])\n",
    "    \n",
    "    y = np.asarray(tempDados['QoE'])\n",
    "    \n",
    "    yFear = np.asarray(dadosFear['QoE'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scalerFear = StandardScaler()\n",
    "    \n",
    "    scaler.fit(X)\n",
    "    \n",
    "    scalerFear.fit(XFear)\n",
    "    \n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    XFear = scalerFear.transform(XFear)\n",
    "    \n",
    "    X_temp = np.zeros((tempDados.shape[0],tempDados.shape[1]))\n",
    "    \n",
    "    X_tempFear = np.zeros((dadosFear.shape[0],dadosFear.shape[1]))\n",
    "    \n",
    "    X_temp[:,:X.shape[1]] = X\n",
    "    \n",
    "    X_tempFear[:,:XFear.shape[1]] = XFear\n",
    "    \n",
    "    X = X_temp\n",
    "    \n",
    "    XFear = X_tempFear\n",
    "    \n",
    "    if(comHora):\n",
    "        X[:, 7:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','TerminoPartida','QoE'], axis=1))])\n",
    "    \n",
    "        XFear[:, 7:-1] = np.asarray(dadosFear[list(dadosFear.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','TerminoPartida','QoE'], axis=1))])\n",
    "    else:\n",
    "        X[:, 6:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','QoE'], axis=1))])\n",
    "    \n",
    "        XFear[:, 6:-1] = np.asarray(dadosFear[list(dadosFear.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','QoE'], axis=1))])\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=porcentagemTeste, random_state=1)\n",
    "    \n",
    "    #Não precisa disso pois o XFear e yFear já são de teste\n",
    "    #X_trainFear, X_testFear, y_trainFear, y_testFear = train_test_split( XFear, yFear, test_size=1.0, random_state=1)\n",
    "    XFear = np.asarray(XFear).astype(np.float32)\n",
    "    yFear = np.asarray(yFear).astype(np.float32)\n",
    "    \n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    modelos = list()\n",
    "    mses = list()\n",
    "    acertos = list()\n",
    "    kFold = StratifiedKFold(n_splits=10)\n",
    "    for train, test in kFold.split(X_train,y_train):\n",
    "        rfr=RandomForestRegressor(n_estimators=n_estimators,max_features=max_features,criterion='mse',bootstrap=True,max_depth=max_depth)\n",
    "        rfr.fit(X_train[train],y_train[train])\n",
    "        y_pred=rfr.predict(X_train[test])#X_test\n",
    "        test_predictions_round = arredondaVetor(y_pred)\n",
    "        porcentagemAcertos = porcentagemAcerto(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"Acerto:\",round(porcentagemAcertos,4))\n",
    "        mse = mean_squared_error(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"MSE: \"+str(mse))\n",
    "        mses.append(mse)\n",
    "        modelos.append(rfr)\n",
    "        acertos.append(porcentagemAcertos)\n",
    "    menorMSE = 99\n",
    "    iMSE = 0\n",
    "    for i in range(len(mses)):\n",
    "        if(mses[i]<menorMSE):\n",
    "            menorMSE = mses[i]\n",
    "            iMSE = i\n",
    "    model = modelos[iMSE]\n",
    "    mse = mses[iMSE]\n",
    "    acerto = acertos[iMSE]\n",
    "    #print(\"Menor MSE: \"+str(mse)+\" com acerto: \"+str(acerto))\n",
    "    y_pred = model.predict(XFear)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos1 = porcentagemAcerto(yFear,test_predictions_round)\n",
    "    #print(\"Acerto com todos dados:\",round(porcentagemAcertos1,4))\n",
    "    mse1 = mean_squared_error(yFear,test_predictions_round)\n",
    "    #print(\"MSE com todos dados: \"+str(mse1))\n",
    "    \n",
    "    return mse,acerto,model,XFear,yFear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44e63d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo tensorFlow MLP com validação com os dados do FEAR\n",
    "def rodarModeloFear(numero,baseDados):\n",
    " with tf.device(dispositivoUsado):\n",
    "    global porcentagemTeste\n",
    "    global porcentagemValidacao\n",
    "    \n",
    "    tempDados = baseDados.copy(deep=True)\n",
    "    tempDados[\"NOME\"].unique()\n",
    "    tempDados[\"Jogo\"].unique()\n",
    "    dummies_jogador = pd.get_dummies(tempDados[\"NOME\"])\n",
    "    dummies_jogo = pd.get_dummies(tempDados[\"Jogo\"])\n",
    "    \n",
    "    tempDados.drop([\"NOME\", \"Jogo\"], axis=1, inplace=True)\n",
    "    \n",
    "    tempDados = tempDados.join(dummies_jogador)\n",
    "    tempDados = tempDados.join(dummies_jogo)\n",
    "    \n",
    "    dadosFear = tempDados[tempDados['FEAR'] == 1]\n",
    "    tempDados = tempDados[tempDados['FEAR'] != 1]\n",
    "    \n",
    "    if(FearValidaComHL2):\n",
    "        tempDados.drop('FEAR', axis=1, inplace=True)\n",
    "        dadosFear['Half-Life 2'] = 1\n",
    "        dadosFear.drop('FEAR', axis=1, inplace=True)\n",
    "\n",
    "    if(comHora):\n",
    "        X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos','TerminoPartida']])\n",
    "    \n",
    "        XFear = np.asarray(dadosFear[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos','TerminoPartida']])\n",
    "    else:\n",
    "        X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos']])\n",
    "    \n",
    "        XFear = np.asarray(dadosFear[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos']])\n",
    "    \n",
    "    y = np.asarray(tempDados['QoE'])\n",
    "    \n",
    "    yFear = np.asarray(dadosFear['QoE'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scalerFear = StandardScaler()\n",
    "    \n",
    "    scaler.fit(X)\n",
    "    \n",
    "    scalerFear.fit(XFear)\n",
    "    \n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    XFear = scalerFear.transform(XFear)\n",
    "    \n",
    "    X_temp = np.zeros((tempDados.shape[0],tempDados.shape[1]))\n",
    "    \n",
    "    X_tempFear = np.zeros((dadosFear.shape[0],dadosFear.shape[1]))\n",
    "    \n",
    "    X_temp[:,:X.shape[1]] = X\n",
    "    \n",
    "    X_tempFear[:,:XFear.shape[1]] = XFear\n",
    "    \n",
    "    X = X_temp\n",
    "    \n",
    "    XFear = X_tempFear\n",
    "    \n",
    "    if(comHora):\n",
    "        X[:, 7:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','TerminoPartida','QoE'], axis=1))])\n",
    "    \n",
    "        XFear[:, 7:-1] = np.asarray(dadosFear[list(dadosFear.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','TerminoPartida','QoE'], axis=1))])\n",
    "    else:\n",
    "        X[:, 6:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','QoE'], axis=1))])\n",
    "    \n",
    "        XFear[:, 6:-1] = np.asarray(dadosFear[list(dadosFear.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','QoE'], axis=1))])\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=porcentagemTeste, random_state=1)\n",
    "    \n",
    "    #Não precisa disso pois o XFear e yFear já são de teste\n",
    "    #X_trainFear, X_testFear, y_trainFear, y_testFear = train_test_split( XFear, yFear, test_size=1.0, random_state=1)\n",
    "    XFear = np.asarray(XFear).astype(np.float32)\n",
    "    yFear = np.asarray(yFear).astype(np.float32)\n",
    "    \n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    class PrintDot(keras.callbacks.Callback):\n",
    "      #def on_epoch_end(self, epoch, logs):\n",
    "      #  if epoch % 100 == 0: print('')\n",
    "      #  print('.', end='')\n",
    "        def on_train_end(self, logs=None):\n",
    "            global QuantasThreadsFinalizaram\n",
    "            QuantasThreadsFinalizaram = QuantasThreadsFinalizaram + 1\n",
    "            print(\"\\nIterações Rodadas: \"+str(QuantasThreadsFinalizaram)+\"\\n\")\n",
    "\n",
    "\n",
    "    EPOCHS = 1000\n",
    "    \n",
    "    verbose = 0\n",
    "    if(exibirRodando):\n",
    "        verbose = 1\n",
    "    \n",
    "\n",
    "    modelos = list()\n",
    "    mses = list()\n",
    "    losss = list()\n",
    "    maes = list()\n",
    "    historys = list()\n",
    "    kFold = StratifiedKFold(n_splits=10)\n",
    "    start = time.process_time()#Contar tempo de execução\n",
    "    for train, test in kFold.split(X, y):\n",
    "\n",
    "        model = build_model_1(X[train])\n",
    "        if(numero == 1):\n",
    "            model = build_model_1(X[train])\n",
    "        elif(numero == 2):\n",
    "            model = build_model_2(X[train])\n",
    "        elif(numero == 3):\n",
    "            model = build_model_3(X[train])\n",
    "        elif(numero == 4):\n",
    "            model = build_model_4(X[train])\n",
    "        elif(numero == 5):\n",
    "            model = build_model_5(X[train])\n",
    "        elif(numero == 6):\n",
    "            model = build_model_6(X[train])\n",
    "        elif(numero == 7):\n",
    "            model = build_model_7(X[train])\n",
    "        elif(numero == 8):\n",
    "            model = build_model_8(X[train])\n",
    "        elif(numero == 9):\n",
    "            model = build_model_9(X[train])\n",
    "            \n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=verbose)\n",
    "    \n",
    "        history = model.fit(X[train], y[train], epochs=EPOCHS,\n",
    "                        validation_split = porcentagemValidacao, verbose=verbose, callbacks=[early_stop])\n",
    "        loss, mae, mse = model.evaluate(X[test], y[test], verbose=verbose)\n",
    "        mses.append(mse)\n",
    "        modelos.append(model)\n",
    "        losss.append(loss)\n",
    "        maes.append(mae)\n",
    "        historys.append(history)\n",
    "    menorMSE = 99\n",
    "    iMSE = 0\n",
    "    for i in range(len(mses)):\n",
    "        if(mses[i]<menorMSE):\n",
    "            menorMSE = mses[i]\n",
    "            iMSE = i\n",
    "    model = modelos[iMSE]\n",
    "    mse = mses[iMSE]\n",
    "    mae = maes[iMSE]\n",
    "    loss = losss[iMSE]\n",
    "    history = historys[iMSE]\n",
    "    global QuantasThreadsFinalizaram\n",
    "    print(str(QuantasThreadsFinalizaram)+\": MSE: \"+str(round(mse,4))+\" tempo: \"+str(round(time.process_time() - start,2)))\n",
    "    QuantasThreadsFinalizaram = QuantasThreadsFinalizaram + 1\n",
    "    \n",
    "    if(exibirRodando):\n",
    "        print(\"Conjunto de testes Mean Abs Error: {:5.2f} QoE\".format(mae))\n",
    "\n",
    "    test_predictions = model.predict(X_test,verbose).flatten()\n",
    "    test_predictions_round = arredondaVetor(test_predictions)\n",
    "    porcentagemAcertos = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    \n",
    "    \n",
    "    test_predictionsFear = model.predict(XFear,verbose).flatten()\n",
    "    test_predictions_roundFear = arredondaVetor(test_predictionsFear)\n",
    "    porcentagemAcertosFear = porcentagemAcerto(yFear,test_predictions_roundFear)\n",
    "    \n",
    "    if(exibirRodando):\n",
    "        plt.scatter(y_test, test_predictions)\n",
    "        #Fazer um MSE e MAE destes dados, para ter também da predição.\n",
    "        plt.xlabel('Valores Reais [QoE]')\n",
    "        plt.ylabel('Predicões [QoE]')\n",
    "        plt.axis('equal')\n",
    "        plt.axis('square')\n",
    "        plt.xlim([0,plt.xlim()[1]])\n",
    "        plt.ylim([0,plt.ylim()[1]])\n",
    "        _ = plt.plot([-100, 100], [-100, 100])\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Porcentagem de acertos arredondado: \"+str(porcentagemAcertos))\n",
    "    \n",
    "        plt.figure()\n",
    "        plt.scatter(y_test, test_predictions_round)\n",
    "        plt.xlabel('Valores Reais [QoE]')\n",
    "        plt.ylabel('Predicões Arredondadas [QoE]')\n",
    "        plt.axis('equal')\n",
    "        plt.axis('square')\n",
    "        plt.xlim([0,plt.xlim()[1]])\n",
    "        plt.ylim([0,plt.ylim()[1]])\n",
    "        _ = plt.plot([-100, 100], [-100, 100])\n",
    "        plt.show()\n",
    "    \n",
    "    resultado = []\n",
    "    resultado.append(loss)\n",
    "    resultado.append(mae)\n",
    "    resultado.append(mse)\n",
    "    resultado.append(porcentagemAcertosFear)\n",
    "    return resultado,yFear,test_predictionsFear,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5e1d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatMap(test_predictions,y_test,nomeHeatmap):\n",
    "    import seaborn as sns\n",
    "    test_predictions_round = arredondaVetor(test_predictions)\n",
    "    x_axis_labels = ['E. Péssimo','Péssimo','Ruim','Regular','bom','Excelente','Ideal'] # labels for x-axis\n",
    "    y_axis_labels = ['E. Péssimo','Péssimo','Ruim','Regular','bom','Excelente','Ideal'] # labels for y-axis\n",
    "    \n",
    "    heatMatrix = np.zeros((7,7))\n",
    "    for x in range(len(y_test)):\n",
    "        intX = int(test_predictions_round[x])\n",
    "        intY = int(y_test[x])\n",
    "        if(intX > 6):\n",
    "            continue\n",
    "        heatMatrix[intX][intY] = heatMatrix[intX][intY] +1\n",
    "                \n",
    "    sns.heatmap(heatMatrix, xticklabels=x_axis_labels, yticklabels=y_axis_labels, cmap=\"Greys\")\n",
    "    plt.savefig(nomeHeatmap+'.png', transparent=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5504242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plota somente para os modelos TensorFlow\n",
    "def plot_melhor(y_test, test_predictions,history,tipo):\n",
    "  with tf.device(dispositivoUsado):\n",
    "    \n",
    "    histi = pd.DataFrame(history.history)\n",
    "    histi['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Erro Médio Absoluto [QoE]')\n",
    "    plt.plot(histi['epoch'], histi['mae'],label='Erro de Treino')\n",
    "    plt.plot(histi['epoch'], histi['val_mae'],label = 'Erro de Validação')\n",
    "    plt.ylim([0,5])\n",
    "    plt.legend()\n",
    "    plt.savefig('melhor'+tipo+'comAcordoMAE.png')\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "    plt.figure()\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Erro Médio Quadratico [$QoE^2$]')\n",
    "    plt.plot(histi['epoch'], histi['mse'],label='Erro de Treino')\n",
    "    plt.plot(histi['epoch'], histi['val_mse'],label = 'Erro de Validação')\n",
    "    plt.ylim([0,20])\n",
    "    plt.legend()\n",
    "    plt.savefig('melhor'+tipo+'comAcordoMSE.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(y_test, test_predictions)\n",
    "    plt.xlabel('Valores Reais [QoE]')\n",
    "    plt.ylabel('Predicões [QoE]')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.xlim([0,plt.xlim()[1]])\n",
    "    plt.ylim([0,plt.ylim()[1]])\n",
    "    _ = plt.plot([-100, 100], [-100, 100])\n",
    "    plt.savefig('melhor'+tipo+'comAcordoPredicoesSemArredondar.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    test_predictions_round = arredondaVetor(test_predictions)\n",
    "    print(\"Porcentagem de acertos arredondado: \"+str(porcentagemAcerto(y_test,test_predictions_round)))\n",
    "    plt.figure()\n",
    "    plt.scatter(y_test, test_predictions_round)\n",
    "    plt.xlabel('Valores Reais [QoE]')\n",
    "    plt.ylabel('Predicões Arredondadas [QoE]')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.xlim([0,plt.xlim()[1]])\n",
    "    plt.ylim([0,plt.ylim()[1]])\n",
    "    _ = plt.plot([-100, 100], [-100, 100])\n",
    "    plt.savefig('melhor'+tipo+'comAcordoPredicoesArredondado.png')\n",
    "    plt.show()\n",
    "    \n",
    "    plot_heatMap(test_predictions,y_test,\"HeatMap_\"+tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5ad9aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodarKNN(baseDados,k):\n",
    "    global porcentagemTeste\n",
    "    global porcentagemValidacao\n",
    "    from sklearn.cluster import KMeans\n",
    "    tempDados = baseDados.copy(deep=True)\n",
    "    tempDados = tempDados[tempDados['Jogo'] != 'FEAR']\n",
    "    tempDados[\"NOME\"].unique()\n",
    "    tempDados[\"Jogo\"].unique()\n",
    "    dummies_jogador = pd.get_dummies(tempDados[\"NOME\"])\n",
    "    dummies_jogo = pd.get_dummies(tempDados[\"Jogo\"])\n",
    "    tempDados.drop([\"NOME\", \"Jogo\"], axis=1, inplace=True)\n",
    "    tempDados = tempDados.join(dummies_jogador)\n",
    "    tempDados = tempDados.join(dummies_jogo)\n",
    "    #print(tempDados.columns)\n",
    "    X=tempDados.iloc[:, 8:17]\n",
    "    #print(X)\n",
    "    if(k == -1):\n",
    "        sse = {}\n",
    "        for k in range(1, 10):\n",
    "            #X['QoE'] = y\n",
    "            kmeans = KMeans(n_clusters=k, max_iter=3000).fit(X)\n",
    "            labels = kmeans.labels_\n",
    "            #print(data[\"clusters\"])\n",
    "            sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
    "        plt.figure()\n",
    "        plt.plot(list(sse.keys()), list(sse.values()))\n",
    "        plt.xlabel(\"Número de grupos\")\n",
    "        plt.ylabel(\"SSE\")\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k, max_iter=3000).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    #X.loc[:,'labels'] = labels\n",
    "    #print(X)\n",
    "    posNomes = list()\n",
    "    nomes = tempDados.NOME.unique()\n",
    "    for i in range(len(nomes)):\n",
    "        for x in range(len(tempDados)):\n",
    "            if(tempDados.at[x,'NOME'] == nomes[i]):\n",
    "                posNomes.append(x)\n",
    "                break\n",
    "    grupoNome = list()\n",
    "    grupos = [[],[],[],[]]\n",
    "    for i in range(len(posNomes)):\n",
    "        grupos[labels[posNomes[i]]].append(nomes[i])\n",
    "        grupoNome.append(nomes[i]+\" Grupo\"+str(labels[posNomes[i]]))\n",
    "        #nomes[i] esta no labels[posNomes[i]]\n",
    "    #print(grupoNome)\n",
    "    for i in range(len(grupos)):\n",
    "        print(\"Grupo \"+str(i+1)+\":\")\n",
    "        for x in range(len(grupos[i])):\n",
    "            print(grupos[i][x],end='  ')\n",
    "        print()\n",
    "    #print(grupos)\n",
    "    for i in range(len(labels)):\n",
    "        tempDados.at[i,'NOME']= 'Grupo'+str(labels[i])\n",
    "    return tempDados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc5a8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gera grupos de jogadores considerando NumJogadores = 9\n",
    "def gerarGrupos(nomes):\n",
    "    opcoes = [[2,2,5],[2,3,4],[3,3,3]]\n",
    "    escolhaOpcao = np.random.randint(0,2)\n",
    "    opcoes = opcoes[escolhaOpcao]\n",
    "    jogadores = np.array(nomes, copy=True)\n",
    "    grupo1 = list()\n",
    "    grupo2 = list()\n",
    "    grupo3 = list()\n",
    "    for i in range(opcoes[0]):\n",
    "        pos = np.random.randint(0,len(jogadores)-1)\n",
    "        grupo1.append(jogadores[pos])\n",
    "        jogadores = np.delete(jogadores, pos)\n",
    "\n",
    "    for i in range(opcoes[1]):\n",
    "        pos = np.random.randint(0,len(jogadores)-1)\n",
    "        grupo2.append(jogadores[pos])\n",
    "        jogadores = np.delete(jogadores, pos)\n",
    "    \n",
    "    for i in range(opcoes[2]-1):\n",
    "        pos = np.random.randint(0,len(jogadores)-1)\n",
    "        grupo3.append(jogadores[pos])\n",
    "        jogadores = np.delete(jogadores, pos)\n",
    "    \n",
    "    grupo3.append(jogadores[0])\n",
    "\n",
    "    grupo1.sort()\n",
    "    grupo2.sort()\n",
    "    grupo3.sort()\n",
    "    \n",
    "    return grupo1,grupo2,grupo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "370768b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retorna um grupo de jogadores ainda não utilizado\n",
    "def dividirGrupos(nomes,agrupJaRealizados,valor):\n",
    "    grupo1,grupo2,grupo3 = gerarGrupos(nomes)\n",
    "    esteAgrup = [grupo1,grupo2,grupo3]\n",
    "    while True:\n",
    "        if esteAgrup in agrupJaRealizados:\n",
    "            grupo1,grupo2,grupo3 = gerarGrupos(nomes)\n",
    "            esteAgrup = [grupo1,grupo2,grupo3]\n",
    "            valor = valor - 1\n",
    "            if valor == 0:\n",
    "                return -1,-1,-1\n",
    "        else:\n",
    "            agrupJaRealizados.append(esteAgrup)\n",
    "            break\n",
    "    \n",
    "    return grupo1,grupo2,grupo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28e1970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RodarKMeans(k,repeticoes,dados2):\n",
    "    teste = dados2.copy(deep=True)\n",
    "    \n",
    "    baseDados = rodarKNN(teste,k)\n",
    "\n",
    "    MSESem,AcertoSem,modeloSem,X_testSem,y_testSem = rodarModeloRF(baseDados) #mse,acerto,model,X_test,y_test\n",
    "    for ABA in range(repeticoes):\n",
    "        MSESem1,AcertoSem1,modeloSem1,X_testSem1,y_testSem1 = rodarModeloRF(baseDados) #mse,acerto,model,X_test,y_test\n",
    "        if(MSESem1<MSESem):\n",
    "            MSESem = MSESem1\n",
    "            AcertoSem = AcertoSem1\n",
    "            modeloSem = modeloSem1\n",
    "            X_testSem = X_testSem1\n",
    "            y_testSem = y_testSem1\n",
    "    \n",
    "    print(\"Resultados Grupo dividido por KMeans com k = \"+str(k))\n",
    "    print(\"MSE treino: \"+str(round(MSESem,2))+\" Acerto treino: \"+str(round(AcertoSem,2)))\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    y_pred = modeloSem.predict(X_testSem)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos1 = porcentagemAcerto(y_testSem,test_predictions_round)\n",
    "    mse1 = mean_squared_error(y_testSem,test_predictions_round)\n",
    "    print(\"MSE validação: \"+str(round(mse1,2))+\" Acerto validação: \"+str(round(porcentagemAcertos1,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ed0a741",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste completo Agrupamento e Fear, MSE e Acerto sem nada inicial:\n",
      "MSE: 0.75 Acerto: 49.07\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'NOME'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ff308393a274>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mRodarKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrepeticoes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdados2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[0mRodarKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrepeticoes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdados2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mRodarKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrepeticoes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdados2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-cdd9082036ad>\u001b[0m in \u001b[0;36mRodarKMeans\u001b[1;34m(k, repeticoes, dados2)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mteste\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdados2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mbaseDados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrodarKNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mteste\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mMSESem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAcertoSem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodeloSem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_testSem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_testSem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrodarModeloRF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseDados\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#mse,acerto,model,X_test,y_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-c2c6e19c61df>\u001b[0m in \u001b[0;36mrodarKNN\u001b[1;34m(baseDados, k)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m#print(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mposNomes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mnomes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempDados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOME\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnomes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempDados\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'NOME'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# EXECUÇÃO EM SI\n",
    "# ESCOLHA DO TIPO DE EXECUÇÃO\n",
    "# E PARAMETROS GERAIS\n",
    "#\n",
    "tipoExecucao = 8\n",
    "#3 - por instancias gerar um grafico de MSE\n",
    "#6 - SHAP do modelo\n",
    "#7 - Testar melhor agrupamento\n",
    "#8 - Testar melhor agrupamento com Random Forest e valida com Fear\n",
    "global NumeroCamadasInternas\n",
    "NumeroCamadasInternas = 96\n",
    "repeticoes = 90\n",
    "nucleos = 1\n",
    "randomForest = True\n",
    "InstanciaInicial = 1700\n",
    "passo = 10\n",
    "NumModelo = 9\n",
    "with tf.device(dispositivoUsado):\n",
    "    #3 - por instancias gerar um grafico de MSE\n",
    "    if(tipoExecucao == 3):\n",
    "        QTDIns = []\n",
    "        MSEIns = []\n",
    "        resultados = []\n",
    "        nInstancias = 20\n",
    "        resultadosIns = []\n",
    "        yIns = []\n",
    "        predicaoIns = []\n",
    "        histIns = []\n",
    "        acertoRFIns = []\n",
    "        for incr in range(InstanciaInicial, numeroInstancias, passo):\n",
    "            rodaDropadoNome = dados.head(incr).copy(deep=True)\n",
    "            rodaDropadoNome = rodaDropadoNome.sample(frac=1).reset_index(drop=True)\n",
    "            if(randomForest):\n",
    "                mse,acerto,model,X_test,y_test = rodarModeloRF(rodaDropadoNome)\n",
    "                for ABA in range(repeticoes):\n",
    "                    mse1,acerto1,model1,X_test1,y_test1 = rodarModeloRF(rodaDropadoNome)\n",
    "                    if(mse1<mse):\n",
    "                        mse = mse1\n",
    "                        acerto = acerto1\n",
    "                QTDIns.append(incr)\n",
    "                MSEIns.append(mse)\n",
    "                acertoRFIns.append(acerto)\n",
    "                print(\".\",end=\" \")\n",
    "            else:\n",
    "                saida,y,predicao,hist = rodarModelo(NumModelo,rodaDropadoNome)\n",
    "                for ABA in range(repeticoes):\n",
    "                    saida1,y1,predicao1,hist1 = rodarModelo(NumModelo,rodaDropadoNome)\n",
    "                    if(saida1[2]<saida[2]):\n",
    "                        saida = saida1\n",
    "                        y = y1\n",
    "                        predicao = predicao1\n",
    "                QTDIns.append(incr)\n",
    "                MSEIns.append(saida[2])\n",
    "                yIns.append(y)\n",
    "                predicaoIns.append(predicao)\n",
    "\n",
    "    #6 - SHAP do modelo\n",
    "    elif(tipoExecucao == 6):\n",
    "        rodarShap(dados)\n",
    "    \n",
    "    #7 - Testar melhor agrupamento\n",
    "    elif(tipoExecucao == 7):\n",
    "        saida,y,predicao,hist = rodarModelo(NumModelo,dados)\n",
    "        MSESem = saida[2]\n",
    "        AcertoSem = saida[3]\n",
    "        SaidaSem = saida\n",
    "        YSem =  y\n",
    "        PredicaoSem = predicao\n",
    "        HistSem = hist\n",
    "        tolerancia = 10000\n",
    "        maxGrupos = 1000\n",
    "        for ABA in range(repeticoes):\n",
    "            saida,y,predicao,hist = rodarModelo(NumModelo,dados)\n",
    "            if(saida[2]<MSESem):\n",
    "                MSESem = saida[2]\n",
    "                AcertoSem = saida[3]\n",
    "                SaidaSem = saida\n",
    "                YSem =  y\n",
    "                PredicaoSem = predicao\n",
    "                HistSem = hist\n",
    "        \n",
    "        \n",
    "        nomes = dados.NOME.unique()\n",
    "        \n",
    "        agrupJaRealizados = list()\n",
    "        MelhorGrupo1,MelhorGrupo2,MelhorGrupo3 = dividirGrupos(nomes,agrupJaRealizados,tolerancia)\n",
    "        \n",
    "        teste = dados.copy(deep=True)\n",
    "        for X in range(len(MelhorGrupo1)):\n",
    "            teste['NOME'] = teste['NOME'].str.replace(MelhorGrupo1[X],\"Grupo1\")\n",
    "        for X in range(len(MelhorGrupo2)):\n",
    "            teste['NOME'] = teste['NOME'].str.replace(MelhorGrupo2[X],\"Grupo2\")\n",
    "        for X in range(len(MelhorGrupo3)):\n",
    "            teste['NOME'] = teste['NOME'].str.replace(MelhorGrupo3[X],\"Grupo3\")\n",
    "        \n",
    "        saida,y,predicao,hist = rodarModelo(NumModelo,teste)\n",
    "        MelhorMSE = saida[2]\n",
    "        MelhorAcerto = saida[3]\n",
    "        MelhorSaida = saida\n",
    "        MelhorY =  y\n",
    "        MelhorPredicao = predicao\n",
    "        MelhorHist = hist\n",
    "        for X in range(maxGrupos):\n",
    "            teste = dados.copy(deep=True)\n",
    "            grupo1,grupo2,grupo3 = dividirGrupos(nomes,agrupJaRealizados,tolerancia)\n",
    "            if(grupo1 == -1 and grupo2 == -1 and grupo3 == -1):\n",
    "                break\n",
    "            for i in range(len(grupo1)):\n",
    "                teste['NOME'] = teste['NOME'].str.replace(grupo1[i],\"Grupo1\")\n",
    "            for i in range(len(grupo2)):\n",
    "                teste['NOME'] = teste['NOME'].str.replace(grupo2[i],\"Grupo2\")\n",
    "            for i in range(len(grupo3)):\n",
    "                teste['NOME'] = teste['NOME'].str.replace(grupo3[i],\"Grupo3\")\n",
    "            saida,y,predicao,hist = rodarModelo(NumModelo,teste)\n",
    "            \n",
    "            if(saida[2]<MelhorMSE):\n",
    "                    MelhorMSE = saida[2]\n",
    "                    MelhorAcerto = saida[3]\n",
    "                    MelhorSaida = saida\n",
    "                    MelhorY =  y\n",
    "                    MelhorPredicao = predicao\n",
    "                    MelhorHist = hist\n",
    "                    MelhorGrupo1 = grupo1\n",
    "                    MelhorGrupo2 = grupo2\n",
    "                    MelhorGrupo3 = grupo3\n",
    "            for ABA in range(repeticoes):\n",
    "                saida,y,predicao,hist = rodarModelo(NumModelo,teste)\n",
    "                if(saida[2]<MelhorMSE):\n",
    "                    MelhorMSE = saida[2]\n",
    "                    MelhorAcerto = saida[3]\n",
    "                    MelhorSaida = saida\n",
    "                    MelhorY =  y\n",
    "                    MelhorPredicao = predicao\n",
    "                    MelhorHist = hist\n",
    "                    MelhorGrupo1 = grupo1\n",
    "                    MelhorGrupo2 = grupo2\n",
    "                    MelhorGrupo3 = grupo3\n",
    "            \n",
    "        print(\"-------------------------Melhor Agrupamento------------------------------\")\n",
    "        print(MelhorGrupo1)\n",
    "        print(\"------------------------\")\n",
    "        print(MelhorGrupo2)\n",
    "        print(\"------------------------\")\n",
    "        print(MelhorGrupo3)\n",
    "        print(\"------------------------\")\n",
    "        print(\"MSE do melhor agrupamento: \"+str(round(MelhorMSE,2))+\" com acerto: \"+str(round(MelhorAcerto,2)))\n",
    "        print(\"MSE SEM agrupamento: \"+str(round(MSESem,2))+\" com acerto: \"+str(round(AcertoSem,2)))\n",
    "        print(\"Gráfico COM agrupamento: \")\n",
    "        plt.rcParams['figure.dpi'] = 600\n",
    "        plot_melhor(MelhorY,MelhorPredicao,MelhorHist,\"comAgrupamento\")\n",
    "        print(\"Gráfico SEM agrupamento: \")\n",
    "        plot_melhor(YSem,PredicaoSem,HistSem,\"semAgrupamento\")\n",
    "        \n",
    "    #8 - Testar melhor agrupamento com Random Forest\n",
    "    elif(tipoExecucao == 8):\n",
    "        dados2 = dados[dados['Jogo'] != 'FEAR']\n",
    "        repeticoes = 90\n",
    "        MSESem,AcertoSem,modeloSem,X_testSem,y_testSem = rodarModeloRF(dados2) #mse,acerto,model,X_test,y_test\n",
    "        tolerancia = 10000\n",
    "        maxGrupos = 1000\n",
    "        for ABA in range(repeticoes):\n",
    "            MSESem1,AcertoSem1,modeloSem1,X_testSem1,y_testSem1 = rodarModeloRF(dados2) #mse,acerto,model,X_test,y_test\n",
    "            if(MSESem1<MSESem):\n",
    "                MSESem = MSESem1\n",
    "                AcertoSem = AcertoSem1\n",
    "                modeloSem = modeloSem1\n",
    "                X_testSem = X_testSem1\n",
    "                y_testSem = y_testSem1\n",
    "        \n",
    "        print(\"Teste completo Agrupamento e Fear, MSE e Acerto sem nada inicial:\")\n",
    "        print(\"MSE: \"+str(round(MSESem,2))+\" Acerto: \"+str(round(AcertoSem,2)))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        RodarKMeans(2,repeticoes,dados2)\n",
    "        RodarKMeans(3,repeticoes,dados2)\n",
    "        RodarKMeans(4,repeticoes,dados2)\n",
    "        \n",
    "        nomes = dados2.NOME.unique()\n",
    "        agrupJaRealizados = list()\n",
    "        MelhorGrupo1,MelhorGrupo2,MelhorGrupo3 = dividirGrupos(nomes,agrupJaRealizados,tolerancia)\n",
    "        \n",
    "        teste = dados2.copy(deep=True)\n",
    "        for X in range(len(MelhorGrupo1)):\n",
    "            teste['NOME'] = teste['NOME'].str.replace(MelhorGrupo1[X],\"Grupo1\")\n",
    "        for X in range(len(MelhorGrupo2)):\n",
    "            teste['NOME'] = teste['NOME'].str.replace(MelhorGrupo2[X],\"Grupo2\")\n",
    "        for X in range(len(MelhorGrupo3)):\n",
    "            teste['NOME'] = teste['NOME'].str.replace(MelhorGrupo3[X],\"Grupo3\")\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        MelhorMSE,MelhorAcerto,MelhorModelo,MelhorX_test,Melhory_test = rodarModeloRF(teste)\n",
    "        for X in range(maxGrupos):\n",
    "            teste = dados2.copy(deep=True)\n",
    "            grupo1,grupo2,grupo3 = dividirGrupos(nomes,agrupJaRealizados,tolerancia)\n",
    "            if(grupo1 == -1 and grupo2 == -1 and grupo3 == -1):\n",
    "                break\n",
    "            for i in range(len(grupo1)):\n",
    "                teste['NOME'] = teste['NOME'].str.replace(grupo1[i],\"Grupo1\")\n",
    "            for i in range(len(grupo2)):\n",
    "                teste['NOME'] = teste['NOME'].str.replace(grupo2[i],\"Grupo2\")\n",
    "            for i in range(len(grupo3)):\n",
    "                teste['NOME'] = teste['NOME'].str.replace(grupo3[i],\"Grupo3\")\n",
    "            MelhorMSE1,MelhorAcerto1,MelhorModelo1,MelhorX_test1,Melhory_test1 = rodarModeloRF(teste)\n",
    "            \n",
    "            if(MelhorMSE1<MelhorMSE):\n",
    "                    MelhorMSE = MelhorMSE1\n",
    "                    MelhorAcerto = MelhorAcerto1\n",
    "                    MelhorModelo = MelhorModelo1\n",
    "                    MelhorX_test = MelhorX_test1\n",
    "                    Melhory_test = Melhory_test1\n",
    "                    MelhorGrupo1 = grupo1\n",
    "                    MelhorGrupo2 = grupo2\n",
    "                    MelhorGrupo3 = grupo3\n",
    "                    print(\"------------------------------------------------------------------\")\n",
    "                    print(\"Melhor MSE encontrado!\")\n",
    "                    print(\"MSE: \"+str(round(MelhorMSE,2))+\" Acerto: \"+str(round(MelhorAcerto,2)))\n",
    "                    from sklearn.metrics import mean_squared_error\n",
    "                    y_pred = MelhorModelo.predict(MelhorX_test)\n",
    "                    test_predictions_round = arredondaVetor(y_pred)\n",
    "                    porcentagemAcertos1 = porcentagemAcerto(Melhory_test,test_predictions_round)\n",
    "                    mse1 = mean_squared_error(Melhory_test,test_predictions_round)\n",
    "                    print(\"MSE validação: \"+str(round(mse1,2))+\" Acerto validação: \"+str(round(porcentagemAcertos1,2)))\n",
    "            for ABA in range(repeticoes):\n",
    "                MelhorMSE1,MelhorAcerto1,MelhorModelo1,MelhorX_test1,Melhory_test1 = rodarModeloRF(teste)\n",
    "                if(MelhorMSE1<MelhorMSE):\n",
    "                    MelhorMSE = MelhorMSE1\n",
    "                    MelhorAcerto = MelhorAcerto1\n",
    "                    MelhorModelo = MelhorModelo1\n",
    "                    MelhorX_test = MelhorX_test1\n",
    "                    Melhory_test = Melhory_test1\n",
    "                    MelhorGrupo1 = grupo1\n",
    "                    MelhorGrupo2 = grupo2\n",
    "                    MelhorGrupo3 = grupo3\n",
    "                    print(\"------------------------------------------------------------------\")\n",
    "                    print(\"Melhor MSE encontrado!\")\n",
    "                    print(\"MSE: \"+str(round(MelhorMSE,2))+\" Acerto: \"+str(round(MelhorAcerto,2)))\n",
    "                    from sklearn.metrics import mean_squared_error\n",
    "                    y_pred = MelhorModelo.predict(MelhorX_test)\n",
    "                    test_predictions_round = arredondaVetor(y_pred)\n",
    "                    porcentagemAcertos1 = porcentagemAcerto(Melhory_test,test_predictions_round)\n",
    "                    mse1 = mean_squared_error(Melhory_test,test_predictions_round)\n",
    "                    print(\"MSE validação: \"+str(round(mse1,2))+\" Acerto validação: \"+str(round(porcentagemAcertos1,2)))\n",
    "        print(\"-------------------------Melhor Agrupamento Random Forest------------------------------\")\n",
    "        print(MelhorGrupo1)\n",
    "        print(\"------------------------\")\n",
    "        print(MelhorGrupo2)\n",
    "        print(\"------------------------\")\n",
    "        print(MelhorGrupo3)\n",
    "        print(\"------------------------\")\n",
    "        print(\"MSE do melhor agrupamento: \"+str(round(MelhorMSE,2))+\" com acerto: \"+str(round(MelhorAcerto,2)))\n",
    "        print(\"MSE SEM agrupamento: \"+str(round(MSESem,2))+\" com acerto: \"+str(round(AcertoSem,2)))\n",
    "        print(\"Gráfico COM agrupamento: \")\n",
    "        plt.rcParams['figure.dpi'] = 600\n",
    "        plot_heatMap(MelhorModelo.predict(MelhorX_test),Melhory_test,\"comAgrupamentoRandomForest\")\n",
    "        print(\"Gráfico SEM agrupamento: \")\n",
    "        plot_heatMap(modeloSem.predict(X_testSem),y_testSem,\"semAgrupamentoRandomForest\")\n",
    "        print(\"-------------------------Validação Random Forest com Fear------------------------------\")\n",
    "        \n",
    "        MSEFear,AcertoFear,ModeloFear,X_testFear,y_testFear = rodarModeloRFcomFear(dados)\n",
    "        for x in range(repeticoes):\n",
    "            MSEFear1,AcertoFear1,ModeloFear1,X_testFear1,y_testFear1 = rodarModeloRFcomFear(dados)\n",
    "            if(MSEFear1<MSEFear):\n",
    "                MSEFear = MSEFear1\n",
    "                AcertoFear = AcertoFear1\n",
    "                ModeloFear = ModeloFear1\n",
    "                X_testFear = X_testFear1\n",
    "                y_testFear = y_testFear1\n",
    "        print(\"-------------------------------------------------------------------------------------------------\")\n",
    "        print(\"MSE validação com fear ambos Jogos: \"+str(round(MSEFear,2))+\" com acerto: \"+str(round(AcertoFear,2)))\n",
    "        print(\"Gráfico Validação Fear: \")\n",
    "        plot_heatMap(ModeloFear.predict(X_testFear),y_testFear,\"validacaoFearRandomForest\")\n",
    "        \n",
    "        teste = dados.copy(deep=True)\n",
    "        teste = teste[teste['Jogo'] != 'Spelunky']\n",
    "        MSEFear,AcertoFear,ModeloFear,X_testFear,y_testFear = rodarModeloRFcomFear(dados)\n",
    "        for x in range(repeticoes):\n",
    "            MSEFear1,AcertoFear1,ModeloFear1,X_testFear1,y_testFear1 = rodarModeloRFcomFear(dados)\n",
    "            if(MSEFear1<MSEFear):\n",
    "                MSEFear = MSEFear1\n",
    "                AcertoFear = AcertoFear1\n",
    "                ModeloFear = ModeloFear1\n",
    "                X_testFear = X_testFear1\n",
    "                y_testFear = y_testFear1\n",
    "        print(\"-------------------------------------------------------------------------------------------------\")\n",
    "        print(\"MSE validação com fear só HL2: \"+str(round(MSEFear,2))+\" com acerto: \"+str(round(AcertoFear,2)))\n",
    "        print(\"Gráfico Validação Fear: \")\n",
    "        plot_heatMap(ModeloFear.predict(X_testFear),y_testFear,\"validacaoFearRandomForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d98e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if(tipoExecucao == 3):\n",
    "  plt.rcParams['figure.dpi'] = 600\n",
    "  with tf.device(dispositivoUsado):\n",
    "    plt.plot(QTDIns, MSEIns)\n",
    "    z = np.polyfit(QTDIns, MSEIns, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(QTDIns,p(QTDIns),\"r--\")\n",
    "    text = f\"Tendência\"\n",
    "    plt.gca().text(0.80, 0.90, text,transform=plt.gca().transAxes,fontsize=10,color=\"red\")\n",
    "    plt.xlabel(\"Número de instâncias\")\n",
    "    plt.ylabel(\"Erro médio quadrático\")\n",
    "    plt.savefig('Erro por instancias com Acordo.png')\n",
    "    plt.show()\n",
    "    \n",
    "    acertos = []\n",
    "    if(randomForest):\n",
    "            acertos = acertoRFIns\n",
    "    else:\n",
    "        for K in range(len(predicaoIns)):\n",
    "            acertos.append(porcentagemAcerto(yIns[K],arredondaVetor(predicaoIns[K])))\n",
    "    plt.figure()\n",
    "    plt.plot(QTDIns, acertos)\n",
    "    z = np.polyfit(QTDIns, acertos, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(QTDIns,p(QTDIns),\"r--\")\n",
    "    text = f\"Tendência\"\n",
    "    plt.gca().text(0.60, 0.90, text,transform=plt.gca().transAxes,fontsize=10,color=\"red\")\n",
    "    plt.xlabel(\"Número de instâncias\")\n",
    "    plt.ylabel(\"Taxa de acerto na validação\")\n",
    "    plt.savefig('Acerto por Instancias com Acordo.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    menor = 45\n",
    "    indiceMenor = 0\n",
    "    tamanhoFinal = len(MSEIns)\n",
    "    tamanhoFinal = tamanhoFinal - (tamanhoFinal/4)\n",
    "    \n",
    "    for x in range(int(tamanhoFinal),len(MSEIns)):\n",
    "        if(MSEIns[x]<menor):\n",
    "            menor = MSEIns[x]\n",
    "            indiceMenor = x\n",
    "    saidaEmTexto = \"Menor MSE : \"+str(menor)+\", acerto:\"+str(acertos[indiceMenor])+\" para \"+str(QTDIns[indiceMenor])+\" Instancias.\"\n",
    "    print(saidaEmTexto)\n",
    "    f = open(\"ultimaExecucaocomAcordoPorInstancias.txt\",\"w+\")\n",
    "    f.write(saidaEmTexto)\n",
    "    f.close()\n",
    "    mse,acerto,model,X_test,y_test = rodarModeloRF(dados)\n",
    "    for ABA in range(20):\n",
    "        mse1,acerto1,model1,X_test1,y_test1 = rodarModeloRF(dados)\n",
    "        if(mse1<mse):\n",
    "            mse = mse1\n",
    "            acerto = acerto1\n",
    "            X_test = X_test1\n",
    "            y_test = y_test1\n",
    "            model = model1\n",
    "    y_pred = model.predict(X_test)\n",
    "    plot_heatMap(y_pred,y_test,\"HEATMAPcomACORDO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08264ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validacaoFear = True\n",
    "if(validacaoFear):\n",
    "    global soHL2\n",
    "    soHL2 = False\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(\"--------------------- Treinamento com HL2 e Spelunky---------------------\")\n",
    "    mse,acerto,model,X_test,y_test = rodarModeloRFcomFear(dados)\n",
    "    for ABA in range(20):\n",
    "        mse1,acerto1,model1,X_test1,y_test1 = rodarModeloRFcomFear(dados)\n",
    "        if(mse1<mse):\n",
    "            mse = mse1\n",
    "            acerto = acerto1\n",
    "            X_test = X_test1\n",
    "            y_test = y_test1\n",
    "            model = model1\n",
    "    print(\"MSE treinamento: \"+str(round(mse,2))+\" acerto: \"+str(round(acerto,2)))\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos1 = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    print(\"MSE validação com Fear: \"+str(round(mse1,2))+\" acerto: \"+str(round(porcentagemAcertos1,2)))\n",
    "    plot_heatMap(y_pred,y_test,\"comAcordoFearAmbos\")\n",
    "    print(\"--------------------- Treinamento somente com HL2---------------------\")\n",
    "    soHL2 = True\n",
    "    mse,acerto,model,X_test,y_test = rodarModeloRFcomFear(dados)\n",
    "    for ABA in range(20):\n",
    "        mse1,acerto1,model1,X_test1,y_test1 = rodarModeloRFcomFear(dados)\n",
    "        if(mse1<mse):\n",
    "            mse = mse1\n",
    "            acerto = acerto1\n",
    "            X_test = X_test1\n",
    "            y_test = y_test1\n",
    "            model = model1\n",
    "    print(\"MSE treinamento: \"+str(round(mse,2))+\" acerto: \"+str(round(acerto,2)))\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos1 = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    print(\"MSE validação com Fear: \"+str(round(mse1,2))+\" acerto: \"+str(round(porcentagemAcertos1,2)))\n",
    "    plot_heatMap(y_pred,y_test,\"comAcordoFearHL2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ff323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
