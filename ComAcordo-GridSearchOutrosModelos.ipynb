{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137a08b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d1c362b0af68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;31m# from tensorflow.python.layers import layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence_feature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mInputSpec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\distribute\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msidecar_evaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\distribute\\sidecar_evaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheckpoint_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutil\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtracking_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0m_PRINT_EVAL_STEP_EVERY_SEC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m60.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_structures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraph_view\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgraph_view_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\graph_view.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaveable_object_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresource_variable_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGradientTape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforwardprop\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mForwardAccumulator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustom_gradient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcustom_gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients_util\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAggregationMethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\forwardprop.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_for\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munconnected_gradients\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUnconnectedGradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\parallel_for\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_for\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_flow_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfor_loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_for\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_flow_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpfor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_for\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbatch_jacobian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_for\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\parallel_for\\gradients.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgradients_impl\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgradient_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_for\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging_ops\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmanip_grad\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath_grad\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptional_grad\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SparseSegmentMean\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_SparseSegmentMeanGrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m   \u001b[1;34m\"\"\"Gradient for SparseSegmentMean.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m   \u001b[0mdim0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   2729\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2730\u001b[0m     \u001b[1;34m\"\"\"Registers the function `f` as gradient function for `op_type`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2731\u001b[1;33m     \u001b[0mgradient_registry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2732\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\registry.py\u001b[0m in \u001b[0;36mregister\u001b[1;34m(self, candidate, name)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# stack trace is [this_function, Register(), user_function,...]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# so the user function is #2.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[0mstack_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstack_index\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36mextract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    360\u001b[0m                 filename, lineno, name, lookup_line=False, locals=f_locals))\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[1;31m# If immediate lookup was desired, trigger lookups now.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\compilerop.py\u001b[0m in \u001b[0;36mcheck_linecache_ipython\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \"\"\"\n\u001b[0;32m    184\u001b[0m     \u001b[1;31m# First call the original checkcache as intended\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkcache_ori\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Then, update back the cache with our data, so that tracebacks related\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;31m# to our compiled codes can be produced.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mcontinue\u001b[0m   \u001b[1;31m# no-op for files loaded via a __loader__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import logging\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "np.random.seed(0)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print(tf.__version__)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "porcentagemTeste = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c2a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('dados-Ambos-Tudo.csv')\n",
    "dados[\"QoE\"] = dados[\"QoE\"] + 3\n",
    "\n",
    "\n",
    "#---------------------------------------------------------\n",
    "#DROPANDO LINHAS COM USO DE CPU E RAM ALTO\n",
    "\n",
    "dados = dados[dados['UsoCpu'] < 81]\n",
    "dados = dados[dados['UsoRam'] < 81]\n",
    "dados = dados[dados['Jogo'] != 'FEAR']\n",
    "\n",
    "#DROPANDO LINHAS COM USO DE CPU E RAM ALTO\n",
    "#---------------------------------------------------------\n",
    "dados['TerminoPartida'] = dados['TerminoPartida'].str.split('-')\n",
    "dados['TerminoPartida'] = dados['TerminoPartida'].str[3]\n",
    "\n",
    "dados = dados.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#Salvando quantos jogadores temos e quantas instancias temos\n",
    "#'NOME'\n",
    "dados.drop(['TempoJogo','UsoCpu', 'UsoRam', 'UsoGpu', 'UsoVram'], axis=1, inplace=True)\n",
    "dados.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83079d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arredondaVetor(vetor):\n",
    "    novoVetor = []\n",
    "    for x in range(len(vetor)):\n",
    "        if(vetor[x]>=0):\n",
    "            floatTeste = vetor[x] - int(vetor[x])\n",
    "            if(floatTeste>=0.5):\n",
    "                novoVetor.append(int(vetor[x])+1)\n",
    "            else:\n",
    "                novoVetor.append(int(vetor[x]))\n",
    "        else:\n",
    "            valor = vetor[x]*(-1.0)\n",
    "            floatTeste = valor - int(valor)\n",
    "            if(floatTeste>=0.5):\n",
    "                novoVetor.append((int(valor)+1)*-1)\n",
    "            else:\n",
    "                novoVetor.append(int(valor)*-1)\n",
    "    return novoVetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4311a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def porcentagemAcerto(vetor1,vetor2):\n",
    "    tamanho = float(len(vetor1))\n",
    "    acertos = float(0)\n",
    "    for x in range(len(vetor1)):\n",
    "        if(vetor1[x]==vetor2[x]):\n",
    "            acertos = acertos + 1.0\n",
    "    acertos = (acertos/tamanho)*100.0\n",
    "    return acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b675bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodarModeloRFParam(baseDados,n_estimators,max_features,max_depth):\n",
    "    global porcentagemTeste\n",
    "    tempDados = baseDados.copy(deep=True)\n",
    "    tempDados[\"NOME\"].unique()\n",
    "    tempDados[\"Jogo\"].unique()\n",
    "    tempDados = tempDados[tempDados['Jogo'] != 'FEAR']\n",
    "    dummies_jogador = pd.get_dummies(tempDados[\"NOME\"])\n",
    "    dummies_jogo = pd.get_dummies(tempDados[\"Jogo\"])\n",
    "    tempDados.drop([\"NOME\", \"Jogo\"], axis=1, inplace=True)\n",
    "    tempDados = tempDados.join(dummies_jogador)\n",
    "    tempDados = tempDados.join(dummies_jogo)\n",
    "    X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos','TerminoPartida']])\n",
    "    y = np.asarray(tempDados['QoE'])\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_temp = np.zeros((tempDados.shape[0],tempDados.shape[1]))\n",
    "    X_temp[:,:X.shape[1]] = X\n",
    "    X = X_temp\n",
    "    X[:, 7:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','TerminoPartida','QoE'], axis=1))])\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=porcentagemTeste, random_state=1)\n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    modelos = list()\n",
    "    mses = list()\n",
    "    acertos = list()\n",
    "    kFold = StratifiedKFold(n_splits=10)\n",
    "    for train, test in kFold.split(X_train,y_train):\n",
    "        rfr=RandomForestRegressor(n_estimators=n_estimators,max_features=max_features,criterion='mse',bootstrap=True,max_depth=max_depth)\n",
    "        rfr.fit(X_train[train],y_train[train])\n",
    "        y_pred=rfr.predict(X_train[test])#X_test\n",
    "        test_predictions_round = arredondaVetor(y_pred)\n",
    "        porcentagemAcertos = porcentagemAcerto(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"Acerto:\",round(porcentagemAcertos,4))\n",
    "        mse = mean_squared_error(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"MSE: \"+str(mse))\n",
    "        mses.append(mse)\n",
    "        modelos.append(rfr)\n",
    "        acertos.append(porcentagemAcertos)\n",
    "    menorMSE = 99\n",
    "    iMSE = 0\n",
    "    for i in range(len(mses)):\n",
    "        if(mses[i]<menorMSE):\n",
    "            menorMSE = mses[i]\n",
    "            iMSE = i\n",
    "    model = modelos[iMSE]\n",
    "    mse = mses[iMSE]\n",
    "    acerto = acertos[iMSE]\n",
    "    #print(\"Menor MSE: \"+str(mse)+\" com acerto: \"+str(acerto))\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos1 = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    #print(\"Acerto com todos dados:\",round(porcentagemAcertos1,4))\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    #print(\"MSE com todos dados: \"+str(mse1))\n",
    "    \n",
    "    return mse,acerto,model,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acharRandomForest():\n",
    "    mse,acerto,model,X_test,y_test = rodarModeloRFParam(dados,1,1,1)\n",
    "    estimators = 1\n",
    "    features = 1\n",
    "    depth = 1\n",
    "    repeticoes = 30\n",
    "    print(\"---------------------prourando melhores HiperParametros RandomForest-----------------------------\")\n",
    "    for n_estimators in range(1,99,2):\n",
    "        for max_depth in range(5,21,1):\n",
    "            for max_features in range(1,7,1):\n",
    "              for ABA in range(repeticoes):\n",
    "                mse1,acerto1,model1,X_test1,y_test1 = rodarModeloRFParam(dados,n_estimators,max_features,max_depth)\n",
    "                if(mse1<mse):\n",
    "                    mse = mse1\n",
    "                    acerto = acerto1\n",
    "                    model = model1\n",
    "                    X_test = X_test1\n",
    "                    y_test = y_test1\n",
    "                    estimators = n_estimators\n",
    "                    features = max_features\n",
    "                    depth = max_depth\n",
    "                print(\".\",end='')\n",
    "\n",
    "    print(\"\\nMenor MSE: \"+str(round(mse,4))+\" acerto: \"+str(round(acerto,4)))\n",
    "    print(\"n_estimators: \"+str(estimators)+\" max_features: \"+str(features)+\" max_depth: \"+str(depth))\n",
    "    print(\"Este modelo com todos os dados agora: \")\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    print(\"Acerto com todos dados:\",round(porcentagemAcertos,4))\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    print(\"MSE com todos dados: \"+str(mse1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb476550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodarModeloMLPParam(baseDados,hidden_layer_sizes,max_iter,act,lr):\n",
    "        \n",
    "    global porcentagemTeste\n",
    "    \n",
    "    tempDados = baseDados.copy(deep=True)\n",
    "    tempDados[\"NOME\"].unique()\n",
    "    tempDados[\"Jogo\"].unique()\n",
    "    tempDados = tempDados[tempDados['Jogo'] != 'FEAR']\n",
    "    dummies_jogador = pd.get_dummies(tempDados[\"NOME\"])\n",
    "    dummies_jogo = pd.get_dummies(tempDados[\"Jogo\"])\n",
    "    tempDados.drop([\"NOME\", \"Jogo\"], axis=1, inplace=True)\n",
    "    tempDados = tempDados.join(dummies_jogador)\n",
    "    tempDados = tempDados.join(dummies_jogo)\n",
    "    X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos','TerminoPartida']])\n",
    "    y = np.asarray(tempDados['QoE'])\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_temp = np.zeros((tempDados.shape[0],tempDados.shape[1]))\n",
    "    X_temp[:,:X.shape[1]] = X\n",
    "    X = X_temp\n",
    "    X[:, 7:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','TerminoPartida','QoE'], axis=1))])\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=porcentagemTeste, random_state=1)\n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    modelos = list()\n",
    "    mses = list()\n",
    "    acertos = list()\n",
    "    kFold = StratifiedKFold(n_splits=10)\n",
    "    for train, test in kFold.split(X_train,y_train):\n",
    "        \n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "        rfr = MLPRegressor(learning_rate_init=lr,activation=act,random_state=1, max_iter=max_iter,hidden_layer_sizes = hidden_layer_sizes)\n",
    "        rfr.fit(X_train[train],y_train[train])\n",
    "        y_pred=rfr.predict(X_train[test])#X_test\n",
    "        test_predictions_round = arredondaVetor(y_pred)\n",
    "        porcentagemAcertos = porcentagemAcerto(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"Acerto:\",round(porcentagemAcertos,4))\n",
    "        mse = mean_squared_error(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"MSE: \"+str(mse))\n",
    "        mses.append(mse)\n",
    "        modelos.append(rfr)\n",
    "        acertos.append(porcentagemAcertos)\n",
    "    menorMSE = 99\n",
    "    iMSE = 0\n",
    "    for i in range(len(mses)):\n",
    "        if(mses[i]<menorMSE):\n",
    "            menorMSE = mses[i]\n",
    "            iMSE = i\n",
    "    model = modelos[iMSE]\n",
    "    mse = mses[iMSE]\n",
    "    acerto = acertos[iMSE]\n",
    "    #print(\"Menor MSE: \"+str(mse)+\" com acerto: \"+str(acerto))\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos1 = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    #print(\"Acerto com todos dados:\",round(porcentagemAcertos1,4))\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    #print(\"MSE com todos dados: \"+str(mse1))\n",
    "    \n",
    "    return mse,acerto,model,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acharMLP():\n",
    "    activation = ['identity','logistic','tanh','relu']\n",
    "    act = activation[0]\n",
    "    LR = [0.001,0.005,0.01,0.1]\n",
    "    lr = LR[0]\n",
    "    hidden_layers = [(32,32,),(32,32,32,),(32,32,32,32,),(64,64,),(64,64,64,),(64,64,64,64,)]\n",
    "    hidden_layer = hidden_layers[0]\n",
    "    max_iters = [250,500,750,1000]\n",
    "    max_iter = max_iters[0]\n",
    "    mse,acerto,model,X_test,y_test = rodarModeloMLPParam(dados,hidden_layer,max_iter,act,lr)\n",
    "    repeticoes = 10\n",
    "    print(\"---------------------prourando melhores HiperParametros MLP-----------------------------\")\n",
    "    for act1 in activation:\n",
    "        for lr1 in LR:\n",
    "            for hidden_layer1 in hidden_layers:\n",
    "                for max_iter1 in max_iters:\n",
    "                    for ABA in range(repeticoes):\n",
    "                        mse1,acerto1,model1,X_test1,y_test1 = rodarModeloMLPParam(dados,hidden_layer1,max_iter1,act1,lr1)\n",
    "                        if(mse1<mse):\n",
    "                            mse = mse1\n",
    "                            acerto = acerto1\n",
    "                            model = model1\n",
    "                            X_test = X_test1\n",
    "                            y_test = y_test1\n",
    "                            hidden_layer = hidden_layer1\n",
    "                            max_iter = max_iter1\n",
    "                            act = act1\n",
    "                            lr = lr1\n",
    "                        print(\".\",end='')\n",
    "\n",
    "    print(\"\\nMenor MSE: \"+str(round(mse,4))+\" acerto: \"+str(round(acerto,4)))\n",
    "    print(\"hidden_layer: \"+str(hidden_layer)+\" max_iter: \"+str(max_iter)+\" act: \"+str(act)+\" LR: \"+str(lr))\n",
    "    print(\"Este modelo com todos os dados agora: \")\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    print(\"Acerto com todos dados:\",round(porcentagemAcertos,4))\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    print(\"MSE com todos dados: \"+str(mse1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodarModeloDTParam(baseDados,criterion,splitter,max_features,max_depth):\n",
    "\n",
    "    global porcentagemTeste\n",
    "    tempDados = baseDados.copy(deep=True)\n",
    "    tempDados[\"NOME\"].unique()\n",
    "    tempDados[\"Jogo\"].unique()\n",
    "    tempDados = tempDados[tempDados['Jogo'] != 'FEAR']\n",
    "    dummies_jogador = pd.get_dummies(tempDados[\"NOME\"])\n",
    "    dummies_jogo = pd.get_dummies(tempDados[\"Jogo\"])\n",
    "    tempDados.drop([\"NOME\", \"Jogo\"], axis=1, inplace=True)\n",
    "    tempDados = tempDados.join(dummies_jogador)\n",
    "    tempDados = tempDados.join(dummies_jogo)\n",
    "    X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos','TerminoPartida']])\n",
    "    y = np.asarray(tempDados['QoE'])\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_temp = np.zeros((tempDados.shape[0],tempDados.shape[1]))\n",
    "    X_temp[:,:X.shape[1]] = X\n",
    "    X = X_temp\n",
    "    X[:, 7:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','TerminoPartida','QoE'], axis=1))])\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=porcentagemTeste, random_state=1)\n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    modelos = list()\n",
    "    mses = list()\n",
    "    acertos = list()\n",
    "    kFold = StratifiedKFold(n_splits=10)\n",
    "    for train, test in kFold.split(X_train,y_train):\n",
    "        \n",
    "        from sklearn import tree\n",
    "        rfr = tree.DecisionTreeRegressor(criterion=criterion,splitter=splitter,max_features=max_features,max_depth=max_depth)\n",
    "        rfr.fit(X_train[train],y_train[train])\n",
    "        y_pred=rfr.predict(X_train[test])#X_test\n",
    "        test_predictions_round = arredondaVetor(y_pred)\n",
    "        porcentagemAcertos = porcentagemAcerto(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"Acerto:\",round(porcentagemAcertos,4))\n",
    "        mse = mean_squared_error(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"MSE: \"+str(mse))\n",
    "        mses.append(mse)\n",
    "        modelos.append(rfr)\n",
    "        acertos.append(porcentagemAcertos)\n",
    "    menorMSE = 99\n",
    "    iMSE = 0\n",
    "    for i in range(len(mses)):\n",
    "        if(mses[i]<menorMSE):\n",
    "            menorMSE = mses[i]\n",
    "            iMSE = i\n",
    "    model = modelos[iMSE]\n",
    "    mse = mses[iMSE]\n",
    "    acerto = acertos[iMSE]\n",
    "    #print(\"Menor MSE: \"+str(mse)+\" com acerto: \"+str(acerto))\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos1 = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    #print(\"Acerto com todos dados:\",round(porcentagemAcertos1,4))\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    #print(\"MSE com todos dados: \"+str(mse1))\n",
    "    \n",
    "    return mse,acerto,model,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af086d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acharDecisionTree():\n",
    "    criterions = ['poisson','mae','mse','friedman_mse']\n",
    "    criterion = criterions[0]\n",
    "    splitters = ['best','random']\n",
    "    splitter = splitters[0]\n",
    "    max_featuress = [1,2,3,4,5,6]\n",
    "    max_features = max_featuress[0]\n",
    "    max_depths = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "    max_depth = max_depths[0]\n",
    "    mse,acerto,model,X_test,y_test = rodarModeloDTParam(dados,criterion,splitter,max_features,max_depth)\n",
    "    repeticoes = 10\n",
    "    print(\"---------------------prourando melhores HiperParametros Decision Tree-----------------------------\")\n",
    "    for criterion1 in criterions:\n",
    "        for splitter1 in splitters:\n",
    "            for max_features1 in max_featuress:\n",
    "                for max_depth1 in max_depths:\n",
    "                    for ABA in range(repeticoes):\n",
    "                        mse1,acerto1,model1,X_test1,y_test1 = rodarModeloDTParam(dados,criterion1,splitter1,max_features1,max_depth1)\n",
    "                        if(mse1<mse):\n",
    "                            mse = mse1\n",
    "                            acerto = acerto1\n",
    "                            model = model1\n",
    "                            X_test = X_test1\n",
    "                            y_test = y_test1\n",
    "                            criterion = criterion1\n",
    "                            splitter = splitter1\n",
    "                            max_features = max_features1\n",
    "                            max_depth = max_depth1\n",
    "                        print(\".\",end='')\n",
    "\n",
    "    print(\"\\nMenor MSE: \"+str(round(mse,4))+\" acerto: \"+str(round(acerto,4)))\n",
    "    print(\"criterion: \"+str(criterion)+\" splitter: \"+str(splitter)+\" max_features: \"+str(max_features)+\" max_depth: \"+str(max_depth))\n",
    "    print(\"Este modelo com todos os dados agora: \")\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    print(\"Acerto com todos dados:\",round(porcentagemAcertos,4))\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    print(\"MSE com todos dados: \"+str(mse1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd048b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodarModeloADA(baseDados,n_estimators,learning_rate,loss):\n",
    "        \n",
    "    global porcentagemTeste\n",
    "    \n",
    "    tempDados = baseDados.copy(deep=True)\n",
    "    tempDados[\"NOME\"].unique()\n",
    "    tempDados[\"Jogo\"].unique()\n",
    "    tempDados = tempDados[tempDados['Jogo'] != 'FEAR']\n",
    "    dummies_jogador = pd.get_dummies(tempDados[\"NOME\"])\n",
    "    dummies_jogo = pd.get_dummies(tempDados[\"Jogo\"])\n",
    "    tempDados.drop([\"NOME\", \"Jogo\"], axis=1, inplace=True)\n",
    "    tempDados = tempDados.join(dummies_jogador)\n",
    "    tempDados = tempDados.join(dummies_jogo)\n",
    "    X = np.asarray(tempDados[['DelayVideo', 'DelayComandos', 'JitterVideo', 'JitterComandos', \n",
    "                              'PerdaVideo', 'PerdaComandos','TerminoPartida']])\n",
    "    y = np.asarray(tempDados['QoE'])\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_temp = np.zeros((tempDados.shape[0],tempDados.shape[1]))\n",
    "    X_temp[:,:X.shape[1]] = X\n",
    "    X = X_temp\n",
    "    X[:, 7:-1] = np.asarray(tempDados[list(tempDados.drop(['DelayVideo', 'DelayComandos', 'JitterVideo',\n",
    "                    'JitterComandos', 'PerdaVideo', 'PerdaComandos','TerminoPartida','QoE'], axis=1))])\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=porcentagemTeste, random_state=1)\n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    modelos = list()\n",
    "    mses = list()\n",
    "    acertos = list()\n",
    "    kFold = StratifiedKFold(n_splits=10)\n",
    "    for train, test in kFold.split(X_train,y_train):\n",
    "        \n",
    "        from sklearn.ensemble import AdaBoostRegressor\n",
    "        from sklearn import tree\n",
    "        #A base precisa utilizar os melhores parametros da decision tree \n",
    "        basee = tree.DecisionTreeRegressor(criterion='mae',splitter='best',max_features=6,max_depth=8)\n",
    "        rfr = AdaBoostRegressor(base_estimator = basee,random_state=1, n_estimators=n_estimators,learning_rate=learning_rate,loss=loss)\n",
    "        rfr.fit(X_train[train],y_train[train])\n",
    "        y_pred=rfr.predict(X_train[test])#X_test\n",
    "        test_predictions_round = arredondaVetor(y_pred)\n",
    "        porcentagemAcertos = porcentagemAcerto(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"Acerto:\",round(porcentagemAcertos,4))\n",
    "        mse = mean_squared_error(y_train[test],test_predictions_round)#y_test\n",
    "        #print(\"MSE: \"+str(mse))\n",
    "        mses.append(mse)\n",
    "        modelos.append(rfr)\n",
    "        acertos.append(porcentagemAcertos)\n",
    "    menorMSE = 99\n",
    "    iMSE = 0\n",
    "    for i in range(len(mses)):\n",
    "        if(mses[i]<menorMSE):\n",
    "            menorMSE = mses[i]\n",
    "            iMSE = i\n",
    "    model = modelos[iMSE]\n",
    "    mse = mses[iMSE]\n",
    "    acerto = acertos[iMSE]\n",
    "    #print(\"Menor MSE: \"+str(mse)+\" com acerto: \"+str(acerto))\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos1 = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    #print(\"Acerto com todos dados:\",round(porcentagemAcertos1,4))\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    #print(\"MSE com todos dados: \"+str(mse1))\n",
    "    \n",
    "    return mse,acerto,model,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961b4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acharAdaBoost():\n",
    "    LR = [0.001,0.005,0.01,0.1]\n",
    "    lr = LR[0]\n",
    "    losss = ['square','linear','exponential']\n",
    "    loss = losss[0]\n",
    "    n_estimatorss = [25,50,75,100,125,150]\n",
    "    n_estimators = n_estimatorss[0]\n",
    "    mse,acerto,model,X_test,y_test = rodarModeloADA(dados,n_estimators,lr,loss)\n",
    "    repeticoes = 10\n",
    "    print(\"---------------------prourando melhores HiperParametros AdaBoost-----------------------------\")\n",
    "    for lr1 in LR:\n",
    "        for loss1 in losss:\n",
    "            for n_estimators1 in n_estimatorss:\n",
    "                    for ABA in range(repeticoes):\n",
    "                        mse1,acerto1,model1,X_test1,y_test1 = rodarModeloADA(dados,n_estimators1,lr1,loss1)\n",
    "                        if(mse1<mse):\n",
    "                            mse = mse1\n",
    "                            acerto = acerto1\n",
    "                            model = model1\n",
    "                            X_test = X_test1\n",
    "                            y_test = y_test1\n",
    "                            n_estimators = n_estimators1\n",
    "                            lr = lr1\n",
    "                            loss = loss1\n",
    "                        print(\".\",end='')\n",
    "\n",
    "    print(\"\\nMenor MSE: \"+str(round(mse,4))+\" acerto: \"+str(round(acerto,4)))\n",
    "    print(\"n_estimators: \"+str(n_estimators)+\" lr: \"+str(lr)+\" loss: \"+str(loss))\n",
    "    print(\"Este modelo com todos os dados agora: \")\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_predictions_round = arredondaVetor(y_pred)\n",
    "    porcentagemAcertos = porcentagemAcerto(y_test,test_predictions_round)\n",
    "    print(\"Acerto com todos dados:\",round(porcentagemAcertos,4))\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse1 = mean_squared_error(y_test,test_predictions_round)\n",
    "    print(\"MSE com todos dados: \"+str(mse1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb6147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acharRandomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05bdc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acharDecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b991ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acharAdaBoost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c083307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acharMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5093021c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
